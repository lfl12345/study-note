# 数据库

## 服务器中的数据库

Redis服务器将所有数据库都保存在服务器状态redisServer结构的db数组中，db数组的每个项都是一个redisDb结构，每个redisDb结构代表一个数据库：

初始化服务器时，程序会根据服务器状态的dbnum属性来决定创建多少个数据库。dbnum有配置文件中的database配置项决定，默认16

```C
struct redisServer { 
    // ... 
    // 一个数组，保存着服务器中的所有数据库 
    redisDb *db; 
    //服务器的数据库数量 
    int dbnum;
    // ... 
};
```

## 切换数据库

每个客户端都会有一个目标数据库，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个指向redisDb结构的指针：

```C
typedef struct redisClient {
	// ... 
    //记录客户端当前正在使用的数据库 
    redisDb *db; 
    // ... 
} redisClient;
```

通过改变redisClient中的属性db指向不同的数据库来实现改变客户端操作的数据库。

## 数据库的键空间

表示数据库的结构体redisDb中的属性dict，他表示了一个字典，用于保存这个数据库所有的键值对

键空间和用户所见的数据库时直接对应的：

* 键空间的键也就是数据库的键，每个键都是一个字符串对象
* 键空间的值也就是数据库的值，每个值可以使字符串对象，列表对象，哈希表对象，集合对象和有序集合对象中的任意一种Redis对象。

```C
typedef struct redisDb { 
    // ... 
    // 数据库键空间，保存着数据库中的所有键值对 
    dict *dict; 
    // ... 
} redisDb;
```

### 读写键空间时的维护操作

当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，包括：

* 在读取一个键之后（包括读操作和写操作），服务器会根据键是否存在来更新服务器的键命中（hit）次数或者键空间不命中（miss）次数，这两个值可以在Info stats命令的keyspace_hits属性和keyspace_misses属性中查看。
* 在读取一个键之后，服务器会更新键的LRU时间，这个值可以用与计算键的闲置时间
* 如果服务器在读取一个键时发现键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其他操作
* 如果有客户端使用watch命令监视了某个键，那么服务器在对被监视的键进行修改之后，会将这个键标记为脏（dirty），从而让事务程序注意到这个键已经被修改过。
* 服务器每一次修改一个键之后，都会对脏（dirty）键的计数加一，这个计数器会触发服务器的持久化以及复制操作。
* 如果服务器开启了数据库通知功能，那么在对键进行修改之后，服务器将按配置发送相应的数据库通知。

# 持久化

持久化的方式：

* 将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注数据本身
* 将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在操作过程

RDB就是第一种持久化的方式，AOF是第二种持久化的方式，Redis都有支持。

## RDB

RDB持久化既可以手动执行，也可以通过服务器配置选项定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。

RDB持久化功能所生成的RDB文件是一个经过压缩的二进制文件，通过该文件可以还原成RDB文件时的数据库状态。

### RDB持久化方式—save

客户端使用命令`save`可以使用RDB方式持久化数据。

手动的执行一次保存操作，在save命令执行的过程中，会直接阻塞Redis服务器进程，知道RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何请求。

save指令的相关配置：

```shell
dbfilename dump.rdb #设置保存的文件名，默认为dump.rdb,一般设置为dump-port.rdb
dir # 设置存储.rdb文件的目录
rdbcompression yes # 设置存储时是否压缩数据，默认yes
rdbchecksum yes # 是否进行RDB文件格式校验，该校验在写文件和读文件过程都会进行
```

### RDB持久化方式—bgsave

因为Redis是单线程的，如果数据库数据较多，save指令会造成进程阻塞，直到RDB文件创建完毕为止，因此会造成数据库效率降低。

因此我们可以使用bgsave指令使redis的持久化操作在后台执行。

调用bgsave指令之后，redis会**fork出来一个子进程**，然后子进程执行持久化数据库的任务，最后将结果写入日志文件中。主进程不会阻塞，直接返回，并继续处理命令请求。

除了前面提到的四个配置之外，bgsave还有一个配置参数：

```shell
stop-writes-on-bgsave-error yes # 后台持久化过程中如果遇到错误是否停止操作，默认yes
```

**在bgsave执行期间，save和bgsave指令都会被回绝**

**同时bgrewriteaof和bgsave两个指令不能同时执行，虽然他俩没啥联系，但是同时启动两个执行大量IO的子进程不是什么好主意，性能会下降。**

### RDB持久方式—自动执行

但是使用客户端输入指令的方式执行持久化操作有很多弊端，例如：不知道何时要执行操作，不知道之前是否执行过操作等。

我们可以通过配置文件进行配置save选项，使满足指定条件的情况下redis自动进行持久化操作。

配置方式：

```shell
save second changes
```

说明：满足限定时间（second）内key的变化数量达到指定数量（changes）即进行持久化

save配置要根据实际业务情况进行设置，频度过高或过低都会出现性能问题，结果可能是灾难性的 

#### 设置保存条件

我们在配置文件中配置的一个或者多个save选项最终都会被设置到redisServer结构中的saveparams属性中，

```c
struct redisServer{
    // 记录保存条件的数组
    struct saveparam *saveparams;
}
```

saveparams是一个数组，数组中的每个元素都是一个saveparams结构，每个saveparams结构都保存了一个save选项设置的保存条件：

```c
struct saveparam{
    // 秒数
    time_t seconds;
    // 修改数
    int changes;
}
```

#### dirty计数器和lastsave属性

除了saveparam数组之外，服务器还维护了一个dirty计数器，以及一个lastsave属性：

* dirty计数器记录距离上一次成功执行save命令或者bgsave命令之后，服务器对数据库状态进行了多少次修改
* lastsave属性是一个UNIX时间戳，记录了服务器上一次成功执行save命令或者bgsave命令的时间。

```c
struct redisServer{
    // 记录保存条件的数组
    struct saveparam *saveparams;
    // 修改计数器
    long long dirty;
    // 上一次执行保存的时间
    time_t lastsave;
}
```

#### 检查保存条件是否满足

Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次，该函数用于对正在运行的服务器进行维护，它的其中一个工作就是检查save选项设置的保存条件是否已经满足，如果满足的话，就执行bgsave命令。

在这个函数中，他会去遍历redisServer结构中的saveparams数组，如果有一对条件满足，那么就会执行bgsave函数。

### RDB的载入工作

RDB文件的载入工作是在服务器启动时自动执行的（阻塞式的），所以Redis并没有专门用于载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。

但是因为AOF文件的更新频率通常比RDB文件的更新频率高，所以，

* 如果服务器开启了AOF持久功能，那么服务器会优先使用AOF文件来还原数据库状态，
* 只有在AOF持久功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。

### 优缺点

优点:

* RDB是一个紧凑压缩的二进制文件，存储效率高
* 内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景
* rdb恢复数据的速度比AOF要快很多
* 应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复

缺点：

* RDB方式无论使用那种方式进行持久化，都无法做到实时持久化，具有较大的可能性丢失数据
* bgsave执行每次运行都要fork子进程，要牺牲一些性能
* Redis众多版本中未进行RDB文件格式的版本统一，有可能出现个版本服务器之间数据格式无法兼容现象

### 在进行bgsave的时候，新来的修改请求怎么办？

在数据量较大的时候进行快照保存，用的时间会相对较长，如果在这个时间段内服务器又收到写请求，那么就不能保证快照的完整性。那么Redis是如何做到的？

Redis使用的是操作系统提供的写时复制技术（Copy-on-write COW），在执行快照的同时，正常处理写操作。

如下图，针对bgsave命令触发的RDB机制来说，如果主线程要修改一块数据，这块数据就被复制一份，生成改数据的副本。此时主线程在副本上进行修改，bgsave子线程继续包原来的数据写入rdb文件中。

换句话说，利用写时复制技术，新进来的修改请求并不会被写入现在正在写的rdb文件中，必须等到下次。使用这种机制可以保证rdb保存数据库数据时快照的一致性。

![image-20220320153804728](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220320153804728.png)

## AOF

与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是通过保存Redis服务所执行的写命令来记录数据库状态的。

RDB的弊端：

* 存储数据量较大，效率较低，基于快照思想，每次读写都是全部数据，当数据量巨大时，效率非常低
* 大数据量下的IO性能较低
* 基于fork创建子进程，内存产生额外消耗
* 宕机带来的数据丢失风险

### AOF概念

AOF（append only file）持久化：以独立日志的方式记录每次写命令，重启时在重新执行AOF文件中命令达到恢复数据的目的。与RDB相比可以简单描述为改变记录数据为记录数据产生的过程

AOF的主要作用是解决了数据持久化的实时性，目前已经是redis持久化的主流方式

可以使用一下配置打开AOF功能：

```shell
appendonly yes|no # 是否开启AOF功能 默认为不开启
appendfsync always|everysec|no # AOF写数据的策略
appendfilename filename # AOF持久化文件名，默认文件名未appendonly.aof，建议配置为appendonly-端口号.aof
dir # AOF持久化保持文件的目录
```

aof写数据的策略：

* always：每次写入操作都同步到AOF文件中，数据零误差，性能较低
* everysec：每秒将缓冲区中的指令同步到AOF文件中，数据准确性高，性能高
* no：由操作系统控制每次同步到AOF文件的周期，整体过程不可控

### AOF持久化的实现

AOF持久化功能的实现可以分为命令追加（append），文件写入，文件同步（sync）三个步骤。

#### 命令追加

当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。

**可以看到aof_buf缓冲区的类型为sds。**

```c
struct redisServer{
    sds aof_buf
}
```

#### AOF文件的写入与同步

Redis服务器进程就是一个事件循环（loop），这个循环中的**文件事件**负责接收客户端的命令请求，以及向客户端发送命令回复，而**时间事件**则负责执行像serverCron函数这样需要定时运行的函数。

AOF文件的写入就是在每次事件循环结束之后，Redis会调用flushAppendOnlyFile函数，考虑是否将缓冲区的内容写入和保存到AOF文件中去。

flushAppendOnlyFile函数的行为由服务器的配置appendfsync选项值来决定（这个**值默认为everysec**）：

![image-20220219102555858](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220219102555858.png)

#### AOF持久化方式的效率和安全对比

* always，每次事件循环都要将aof_buf缓冲区中的所有内容写入AOF文件，并同步AOF文件，因此always效率是最慢的一个，安全性最高，不会有数据的丢失
* everysec，每次事件循环都要将aof_buf缓冲区中的所有内容写入AOF文件，并且每隔一秒就要在子线程中对AOF文件进行一次同步，效率上来说，足够块，并且就算出现故障，也就会失去1秒的数据。
* no，每次事件循环都要将aof_buf缓冲区中的所有内容写入AOF文件，至于什么时候对AOF文件进行同步，则由操作系统控制，所以no模式是最快的，但是出现故障的代价可能会很大。

### AOF文件的载入和数据还原

Redis读取AOF并还原数据库状态的详细步骤：

1. 打开AOF文件
2. 创建一个不带网络的伪客户端，用于执行AOF文件中的命令。因为Redis中的命令只能在客户端上下文中执行。
3. 从AOF中读取并解析一条命令
4. 使用伪客户端执行被读出来的写命令
5. 重复3和4，直到所有写命令都被处理完毕为止。

![image-20220320155439278](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220320155439278.png)



### AOF重写

Redis4提供了AOF混合持久化，通过aof-use-rdb-preamble配置进行控制，默认为yes，代表启用，配置为no则可以禁用。

开启AOF混合持久化后，AOF重写时，会将Redis数据以RDB格式保存到新文件（生成文件更小，加载速度更快），再将重写缓冲区的增量命令以AOF格式写入文件。

关闭AOF混合持久化后，AOF重写时，则将Redis所有数据转换为写入命令写入新文件。

AOF重写过程可以分为4步骤：

1. fork一个子进程，称为AOF进程，AOF进程负责将当前内存数据保存到一个新文件中
2. AOF进程将步骤1执行期间主进程执行的增量命令（这些命令保存在重写缓冲区，重写缓冲区在服务器创建子进程之后开始使用）写入到新文件中，最后结束AOF进程
3. 当子进程完成AOF重写之后，会给主进程发送信号，父进程接收到信号后，调用信号处理函数，并执行：
   1. 将步骤2执行期间主进程执行的增量命令也写入新文件中，此阶段会阻塞主进程
   2. 原子替换AOF文件，AOF重写完成




## RDB和AOF对比

![image-20220219104045010](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220219104045010.png)

# 事件

Redis是一个时间驱动程序，服务器需要处理一下两类事件：

* 文件事件（file event）：Redis服务器通过套接字与客户端（或者其他Redis服务器）进行连接，而文件事件就是服务器对套接字操作的抽象。

  服务器与客户端的通信会产生相应的文件事件，而服务器则通过监听并处理这些事件来完成一系列网络操作。

* 时间事件（time event）：Redis服务器中的一些操作（例如serverCron函数）需要在给定时间点执行，而时间事件就是服务器对这类定时操作的抽象。

## 文件事件

Redis基于Reactor模式开发了自己的网络事件处理器：文件事件处理器

* 文件事件处理器使用IO多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

* 当被监听的套接字准备好执行连接应答（accept），读取（read），写入（write），关闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

虽然文件事件处理器以单线程方式运行，但通过使用IO多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与Redis服务器中其他同样以单线程方式运行的模块进行对接，保持了Redis内部单线程设计的简单性。

### 文件事件处理器的构成

文件事件处理器的四个组成部分，它们分别是套接字，IO多路复用程序，文件事件分派器（dispatcher），以及事件处理器。

文件事件是对套接字操作的抽象，每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时，就会产生一个文件事件。

尽管多个文件事件可能会并发的出现，但是**IO多路复用程序**总是会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序，同步，每一次一个套接字的方式向文件事件的方式向**文件事件分派器**传送套接字。

**文件事件分派器**接收到IO多路复用程序传来的套接字，并根据套接字产生的事件的类型，调用相应的**事件处理器**。

服务器会为不同任务的套接字关联不同的事件处理器，这些处理器是一个个函数，他们定义了某个事件发生时，服务器应该执行的动作。

### IO多路复用程序的实现

Redis程序会在编译时自动选择系统中性能最高的IO多路复用函数库来作为RedisIO多路复用程序底层实现。

### 事件类型

IO多路复用监听ae_readable事件和ae_writable事件，

* 当socket变得可读时（客户端对应的socket执行write，close）或者有新的可应答（acceptable）socket出现时，套接字产生ae_readable事件。
* 当socket变得可写时（客户端socket执行read），socket产生ae_writable事件。

如果一个socket即可读有可写的话，服务器会先读套接字然后再写套接字。

### 文件事件的处理器

* 连接应答处理器
* 命令请求处理器
* 命令回复处理器
* 复制处理器——主从服务器复制功能

## 时间事件

Redis的时间事件可以分为两类：

* 定时事件：让一段程序在指定的时间之后执行一次。就执行一次
* 周期事件：让一段程序每隔指定时间就执行一次。执行很多次

一个时间事件由以下三个属性构成：

* id，服务器为时间事件创建的全局唯一的id
* when，毫秒精确的UNIX时间戳，记录了时间事件的到达时间
* timeProc：时间事件处理器，一个函数。

一个时间事件是定时事件还是周期事件取决于时间事件处理器的返回值：

* 如果时间事件处理器返回值为ae_nomore，那么这个事件为定时事件：该事件在达到一次之后会被删除。
* 如果时间事件处理器返回值为非ae_nomore的整数值，那么这个事件为周期性事件：当一个事件到达后，服务器会根据事件处理器返回的值，对时间事件的when属性进行更新，让这个事件在一段时间之后再次到达。

在redis 3 版本中，只有周期时间事件，没有定时时间事件。

### 时间事件的实现

服务器将所有时间事件都放在一个无序链表中，每当时间事件周期性的运行时，他就遍历整个链表，查找所有已到达的时间事件，并调用相应的时间事件处理器。

### serverCron函数

serverCron函数负责定期对Redis自身的资源和状态进行检查和调整，从而确保服务器可以长期，稳定地运行，serverCron的主要功能有：

* 更新服务器的各类统计信息，例如时间，内存占用，数据库占用
* 清理数据库中的过期键值对
* 关闭和清理连接失效的客户端
* 尝试进行AOF或RDB持久化
* 如果服务器是主服务器，那么对从服务器进行定期同步
* 如果处于集群模式，对集群进行定期同步和连接测试

用户可以通过修改**hz选项**来调整serverCron的每秒执行次数。



# 服务器

## 命令请求的执行过程

发送命令请求

* 客户端将命令请求转换为**协议格式**，通过连接到服务器的套接字，将协议格式的命令请求发送给服务器。

读取命令请求

* 读取套接字中协议格式的命令请求，并将其保存到客户端状态的输入缓冲区中
* 对输入缓冲区中的命令请求进行解析，提取出命令请求中包含的命令参数，以及命令参数的个数，保存到clients属性的argv和argc属性中
* 调用命令执行器，执行客户端指定的命令

命令执行器：

1. 查找命令实现：通过命令表（字典）和客户端状态的argv[0]属性查找执行的命令
2. 执行预备操作，检查参数是否合法，用户是否有权限等
3. 调用命令的实现函数，
4. 执行后续工作：添加慢查询日志，AOF持久操作，向从服务器复制操作。

将命令回复发送给客户端：

* 命令实现函数将命令回复保存到客户端的输出缓冲区，并为客户端的socket关联命令回复处理器，当客户端socket变为可写状态时，服务器就会执行命令回复处理器，将保存在客户端输出缓冲区中的命令发送给客户端。然后清空客户端状态缓冲区

## serverCron函数

执行的操作：

* 更新服务器时间缓存，如果服务器每次获取当前时间都去调用系统调用，那么会影响Redis的效率，因此serverCron函数默认100毫秒一次更新服务器状态中当前时间缓存
* 更新LRU时钟，服务器状态的lruclock属性保存了服务器的LRU时钟，同时RedisObject对象中保存了lru属性，表示对象最近被访问的时间，使用lruclock-lru表示对象的空转时间，用于删除策略中实现对象的淘汰
* 管理数据库资源，serverCron每次执行会调用databasesCron函数，这个函数会对服务器中的一部分数据库进行检查，删除其中的过期键，并在需要时，对字典进行收缩操作。
* 执行被延迟的bgrewriteaof，服务器在执行bgsave期间，如果接收到bgrewriteaof那么服务器会将bgrewriteaof命令的执行时间延迟到bgsave命令执行之后
* 将AOF缓冲区中的内容写入AOF文件，根据AOF持久化策略的配置，将AOF缓冲区中的数据写入AOF文件



# Redis事务

redis的事务提供了一种将多个命令请求打包，然后一次性，按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而该去执行其他客户端的命令，他会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令。

但是redis不支持回滚，如果事务中有命令执行失败了，那么redis会继续执行后续命令而不是回滚。

## 事务的基本操作

开启事务：multi，设置事务的开启位置，此指令执行后，后续所有指令均会加入到事务中

执行事务：exec，设置事务的结束位置，同时执行事务，与multi成对出现，成对使用

加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行exec命令才开始执行

**如果在事务定义的过程中出现了问题怎么办？**

取消事务：discard，终止当前事务，发生在multi之后，exec之前

**事务注意事项：**

* 定义事务的过程中，命令格式输入错误：
  * 整体事务中所有命令均不会执行。包括那些语法正确的命令。
* 命令格式正确，但是语法错误，无法执行 
  * 能正确运行的命令会运行，运行错误的命令不会运行，不会回滚

## 事务的实现

一个事务从开始到结束会经历三个阶段：事务开始，命令入队，事务执行

### 事务开始

multi命令标志着事务	的开始，

multi命令可以将执行该命令的客户端从非事务状态切换为事务状态，这一切换是通过在客户端状态的flags属性中打开REDIS_MULTI标识来完成的。

### 命令入队

当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。

但是，当一个客户端处于事务状态时，服务器会根据客户端发来的不同命令执行不同的操作：

* 如果是exec，discard，watch，multi命令中的一个，那么服务器会立即执行这个命令。
* 如果不是，将命令放入一个事务队列中，然后返回queued回复。

### 事务队列

每个Redis客户端都有自己的事务状态，这个事务状态保存在客户端状态的mstate属性中，

事务状态包含一个事务队列，以及一个入队命令的计数器（也可以说是事务队列的长度）

事务队列以先进先出（FIFO）的方式	保存入队命令，

### 执行事务

当一个处于事务状态的客户端向服务器发送EXEC命令时，这个EXEC命令将立即被服务器执行，服务器会遍历这个客户端的事务队列，执行队列中保存的所有命令，最后将执行命令的结果全部返回给客户端。

## watch命令的实现

watch命令是一个乐观锁，它可以在exec命令执行之前，监视任意数量的数据库键，并在exec命令执行时，检查被监视的键是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空恢复。

可以使用unwatch命令取消对所有key的监视。

**使用watch监视数据库键**

每个Redis数据库（redisDb结构体）都保存一个watched_keys字典，该字典的键是数据库中被监视的Redis键，字典的值是监视字典键的所有客户端链表。

**监视机制的触发**

对所有数据库进行修改的命令，在执行之后都会调用touchWatchKey函数对watched_keys字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键，

* 如果有，那么touchWatchKey函数会将监视被修改键的客户端的Redis_dirty_cas标识打开，表示客户端的事务安全性被破坏

**判断事务是否安全**

当服务器接收到一个客户端发来的**exec命令**时，服务器会根据这个客户端是否打开了redis_dirty_cas标识来决定是否执行事务：

* 如果客户端的redis_dirty_cas标识已经被打开，那么说明客户端所监视的键中，至少一个键已经被修改，那么客户端提交的事务已经不安全，所以服务器拒绝执行客户端提交的事务
* 如果客户端的redis_dirty_cas标识没有被打开，事务是安全的，服务器将执行客户端提交的这个事务。



# 分布式锁

使用setnx设置一个公共锁，

```shell
setnx lock-key value
```

利用setnx命令的返回值特性，有值则返回设置失败，没有值则返回设置成功

* 对于返回设置成功的，代表获取到了锁，可以执行下一步操作
* 对于返回设置失败的，不具有控制权，排队或者等待

当获取到锁的线程完成操作之后，通过del操作释放锁

## 分布式锁改良

依赖setnx的分布式锁机制，如果客户端获取到锁之后宕机，那么锁就不会释放，因此我们必须给这个锁设置一个超时时间，当客户端获取到这个锁一段时间之后，如果超时，那么锁将自动释放。

使用expire或者pexpire命令进行设置超时时间的任务。

这个超时时间的选择可以通过大量的测试，也就是可以看看每次获取到锁的线程在执行多长时间后就会释放锁，根据大量的实验，可以取一个最大值作为锁的超时时间。

# Redis的删除策略

Redis可以挺过ttl命令获取对应key在内存中的状态：

* xx：还有xx剩余时间就过期的数据
* -1：永久有效的数据
* -2：已经过期的数据 或者 被删除的数据 或者 从未存在过的数据

但是Redis中已经过期的数据不一定被真正删除了，因为考虑到CPU的使用率和性能原因，由于删除操作并不太重要，因此可以暂缓删除操作，让它在以后CPU空闲的时候在删除。具体怎么删除，需要看使用的什么删除策略

## 设置键的过期时间

Redis有四种不同的命令设置键的过期时间：

* expire key ttl，将key的生存时间设置为ttl秒
* pexprie，设置为ttl毫秒
* expireat key timestamp 将key过期时间设置为timestamp所指定的秒数时间戳
* pexpireat 将key过期时间设置为timestamp所指定的毫秒数时间戳。

虽然有四种，但是实际上expire，pexprie，expireat三个命令都是使用pexpire命令来实现的：无论客户端执行的是以上四个命令中的那一个，经过转换之后，最终执行效果都和pexpireat命令一样，最终都会调用同一个方法。

### 保存过期时间

redisDb的expires字典中保存了数据库中所有键的过期时间，我们称这个字典为过期字典：

* 过期字典的键是一个指针（地址），这个指针指向键空间中的某个键对象（也就是某个数据库键）
* 过期字典的值是一个long long类型的整数，这个整数保存了键所指向的数据库键的过期时间——一个毫秒精度的UNIX时间戳

```C
typedef struct redisDb { 
    // ... 
    // 过期字典，保存着键的过期时间
	dict *expires; 
    // ... 
} redisDb;
```

当客户端执行设置过期时间的四个命令时，服务器会在数据库的过期字典（expires）中关联给定的数据库键和过期时间

### 移除过期时间

persist命令可以移除一个键的过期时间，persist命令就是pexpireat命令的反操作：persist命令在过期字典中查找给定的键，并解除和键（过期时间）在过期字典中的关联

### 计算并返回剩余生存时间

ttl命令以秒为单位返回键的生存时间

而pttl命令以毫秒为单位返回键的剩余生存时间

这两个命令通过计算键的过期时间和当前时间之间的差值来实现的。

### 过期时间的判定

1. 检查给定键是否存在于过期字典：如果存在，那么取得键的过期时间
2. 检查当前UNIX时间戳是否大于键的过期时间：如果是的话，那么键已经过期；否则的话，键未过期

## 数据删除策略

要设计这种删除策略的原因：在内存占用和CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或内存泄漏

**定时删除和定期删除为主动删除策略，惰性删除为被动删除策略。**

### 定时删除

创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作

优点：对内存最友好，节约内存，到时就删除，快速释放掉不必要的内存占用

缺点：

* CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量

* 除此之外，创建一个定时器需要用到Redis服务器中的时间事件，而当前时间事件的实现方式—无序链表，查找一个事件的时间复杂度为O(N)—并不能高效地处理大量时间事件

总结：用处理器性能换区存储空间

### 惰性删除

数据到达过期时间，不做处理，等下次访问该数据时：

* 如果未过期，返回数据
* 发现已经过期，删除，返回不存在

优点：节约CPU性能，发现必须删除的时候才删除

缺点：内存压力很大，出现长期占用内存的数据

总结：用存储空间换处理器性能（拿空间换时间）

### 定期删除

以上两种方案是两种极端，可以使用一种折中的方案

周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度。并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响

特点：

* CPU性能占用设置有峰值，检测频度可自定义设置
* 内存压力不是很大，长期占用内存的冷数据会被持续清理

总结：周期性抽查存储空间（随机抽查，重点抽查）

## 删除策略的实现

Redis服务器中实际使用的是惰性删除和定期删除两种策略：

### 惰性删除的实现

当用户查询键时，检测键是否过期，如果键已经过期，则删除该键。这个操作是由expireIfNeeded函数完成的。

### 定期删除的实现

过期键的定期删除策略由activeExpireCycle函数实现，每当Redis服务器周期性操作serverCron函数执行时，activeExpireCycle函数就会被调用，在它规定的时间内，多次遍历服务器中的各个数据库，从数据库的expires字典中随机检查一部分过期时间，并删除其中的过期键。

* 服务启动时读取server.hz参数配置的值
* 每秒钟执行server.hz次serverCron函数，然后这个函数会调用activeExpireCycle函数
* activeExpireCycle函数对每个数据库的过期字典（expires）逐一进行检查，函数每次执行固定的时间250ms/server.hz
* 对每个过期字典检查时，随机挑选W个key进行检查
  * 如果key超时，删除key
  * 如果这一轮中删除的key的数量大于W*25%，循环该过程
  * 如果这一轮中删除的key的数量小于W*25%，检查下一个expires
  * W取值=active_expire_cycle_lookups_per_loop属性值
* 参数current_db用于记录activeExpireCycle进入到那个库的expires执行
* 如果activeExpireCycle执行时间到期，下次从current_db继续向下执行

## 数据淘汰机制

当新数据进入redis时，如果内存不够用怎么办？此时就需要使用数据淘汰机制将内存中的数据删除一部分用来缓存新的数据。

在redis执行每一个命令之前，都会调用freeMemoryIfNeeded函数检测内存是否充足，如果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。

影响数据逐出的相关配置：

```shell
maxmemory # 最大可用内存，占用物理内存的比例，默认0，表示不限制
maxmemory-samples # 每次选取待删除数据的个数，选取数据时并不会全库扫描，导致严重性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-policy # 删除策略，达到最大内存后，对被选出来的数据进行删除的策略
```

Redis支持一下数据逐出算法：

* 检测会过期的数据（expires数据字典中的数据）
  * volatile-lru：挑选最近最少使用的数据淘汰
  * volatile-lfu：挑选最近使用次数最少的数据淘汰
  * volatile-ttl：挑选将要过期的数据淘汰
  * volatile-random：任意选择数据淘汰
* 检测全库数据（所有数据，在dict数据字典上的数据）
  * allkeys-lru：挑选最近最少使用的数据淘汰
  * allkeys-lfu：挑选最近使用次数最少的数据淘汰
  * allkeys-random：任意选择数据淘汰
* 放弃数据淘汰
  * no-eviction(驱逐)：禁止驱逐数据（redis4中的默认策略）

通常使用双向链表实现LRU算法，但是由于使用链表记录所有键的访问顺序需要耗费过多内存，所以Redis并没有采用这种方式。

Redis使用的是LRU近似算法，从数据中获取部分随机数据作为样本数据，并将样本数据中最合适的数据淘汰。LFU算法那同样使用类似的近似算法。

为了实现LRU和LFU近似计算，Redis使用redisObject.lru记录键的最新访问时间（LRU时间戳）或键的访问频率（LFU计数），每次查找键都会更新redisObject.lru属性

如果使用LFU，则调用updateLFU函数更新LFU计数

# 主从复制

主从复制机制的作用：

* 数据冗余，将数据热备份到从结点，即使主节点由于磁盘损坏丢失数据，从结点依然保留数据副本
* 读写分离，可以有主节点提供写服务，从结点提供读服务，提升Redis服务整体吞吐量
* 故障恢复，主节点故障下线后，可以手动将从结点切换为主节点，继续提供服务
* 高可用基础，主从复制是Sentinel和Cluster机制的基础，Sentinel和Cluster都实现了故障转移，即主节点故障停止后，Redis负责选择一个从结点切换为主节点，继续提供服务

主从复制的流程可以分为三个阶段：

1. 握手阶段：主从连接成功后，从结点需要将自身信息（IP，端口）发送给主节点，以便主节点能认识自己

2. 同步阶段：从结点连接主节点后，需要先同步数据，数据达到一致（或者只有最新的变更不一致）后才进入复制阶段

   Redis支持两种同步机制

   * 全量同步：从结点发送psync ？ -1，要求进行全量同步，主节点返回响应+fullresync，表示同意全量同步。随后，主节点生成RDB数据并发送给从结点，这种方式常用于新的从结点首次同步数据
   * 部分同步：从结点发送命令psync replid offset，要求进行部分同步，主节点相应+continue，表示同意部分同步。主节点只需要把复制积压区中offset偏移量之后的命令发送给从结点即可（主节点会将执行的写命令都写入复制积压区）。这种方式常用于主从连接断开重连时同步数据。如果offset不在复制积压区中，那么主节点也会返回+fullresync，要求进行全量复制

3. 复制阶段：主节点在运行期间，将执行的写命令传播给从结点，从结点接收并执行这些命令，从而达到复制数据的效果。Redis使用的是异步复制，主节点传播命令后，并不会等待从结点返回ack确认，异步复制的优点是低延时和高性能，缺点是可能在短期内主从结点数据不一致

## 主从握手流程

1. 从结点设置主服务器的地址和端口。当客户端给从服务器发送replicaof masterip masterport命令或者从服务器配置文件中有配置replicaof masterip masterport，从服务器就将主服务器的地址和端口保存到服务器状态的masterhost和masterport属性中。

2. 从结点使用replicaofCommand函数处理replicaof命令，

   1. 如果处理的命令时replicaof no one，则将当前服务器专换为主节点，取消原来的主从复制关系，退出函数
   2. 调用replicationsetmaster函数，与给定服务器建立主从关系，这个函数会断开从结点之前的主从关系，断开从结点的从结点，将从结点的状态变为正在连接状态

   当从结点server.repl_state进入**repl_state_connect**正在连接状态后，**主从复制流程已已经开始**

3. serverCorn时间事件负责对**repl_state_connect**状态进行处理，如果服务器处于正在连接状态，那么会调用**connectWithMaster**函数进行处理，这个函数负责建立主从网络连接。

   当socket连接成功之后，从服务器为这个套接字关联一个专门用于处理复制工作的文件事件处理器，这个处理器负责执行后续的复制工作。

   主服务器将该套接字创建相应的客户端状态，并将从服务器看做是一个连接到主服务器的客户端来看待

4. 网络连接成功后，从结点调用用**syncWithMaster**函数，进入握手阶段。

5. 从结点发送ping命令，进入repl_state_reveive_pong状态。

   * 通过ping命令可以检查套接字的读写状态
   * 检查服务器是否能正确处理命令请求

   > ping命令的回复情况
   >
   > 1. 主服务器回复超时，从服务器断开并重新创建连向主服务器的套接字。 
   > 2. 主服务器返回错误，从服务器断开并重新创建连向主服务器的套接字。 
   > 3. 主服务器返回pong，从服务器可以继续执行复制工作的下个 步骤

6. 从服务器接收到pong返回之后，进入repl_state_send_auth状态。如果从服务器开启了主从认证，那么发送auth命令以及认证密码，进入repl_state_receive_auth状态；如果从服务器没有开启主从认证，直接进入repl_state_send_port状态。

   > 在认证阶段，主服务器设置了不同的密码，或者主服务器设置了密码，从服务器没有设置，或者主服务器没有设置，从服务器设置了，都会造成从服务器断开并重新创建向主服务器的套接字或者不再连接

7. 身份验证之后，进入repl_state_send_port状态，从服务器发送自己的端口信息给主节点。从服务器执行命令replconf listening-port \<port-number>，向主服务器发送从服务器的监听端口号。进入repl_state_receive_port状态

8. 读取相应没问题之后，从结点进入repl_state_send_ip状态，发送从结点IP地址给主节点，然后进入repl_state_receive_ip状态

9. 读取响应没问题之后，从结点进入repl_state_send_capa状态，发送capa信息，进入repl_state_receive_capa状态

   > capa全称为capabilities，代表从结点支持的复制能力

10. 读取响应没问题之后，从结点进入repl_state_send_psync状态，发送psync命令到主节点，发起同步流程，进入repl_state_receive_psync状态

执行到这里，主从握手阶段已经完成，server.repl_state必须处于repl_state_receive_psync状态，否则报错

## 同步阶段

以下的同步步骤假设从服务器是第一次连接主服务器

### 全量复制

1. 因为从服务器的cached_master不存在（在从服务器中的主节点缓存），因此使用全量复制，从服务器发送psync ？ -1命令
2. 主服务器收到从服务器第一次发送的全量复制的指令后，将该客户端添加到server.slaves中，此时如果主节点的复制积压区没创建，创建复制积压区
3. 主节点生成一个RDB文件，并发送到从结点
4. 此时从结点接收到主节点的返回信心
   1. 如果主节点不支持psync，那么重新发送sync命令
5. 从结点清除旧数据，载入接收到的RDB文件
6. 主节点将生成RDB文件以及发送过程中又接收到的指令（这些指令以AOF的形式存在复制缓冲区中）
7. 从结点接收到这些同步信息后，先执行bgrewriteaof，然后将数据同步

### 部分复制

由于全量复制在主节点数据量较大的时候效率很低，因此redis还支持了部分复制，主要用于解决在断网一段时间后的主从数据同步问题。

#### 复制偏移量

主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。

offset可以用来判断主从数据库的一致性：

* 如果两者offset相同，则一致
* 如果offset不同，则不一致，如果复制积压缓冲区中还存在着这个offset之后的数据，此时可以根据两个offset找出从节点缺少的那部分数据。

#### 复制积压缓冲区

复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区

在命令传播阶段，主节点除了将命令发送给从结点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还村粗了其中的么个字节对应的复制偏移量（offset）。由于复制积压缓冲区是定长且是先进先出，所以它保存的是主节点最近执行的写命令，时间较早的命令会被挤出缓冲区。

由于缓冲区长度固定，因此可以备份的写命令业有限，当主从结点offset的差距过大 超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。

从结点将offset发送给主节点之后，主节点会更具offset决定是否执行部分复制：

* 如果offset偏移量之后的数据，仍然在复制缓冲区中，则执行部分复制
* 如果offset偏移量之后的数据已经不在复制积压缓冲区中，则执行全量复制

#### 服务器运行ID（runid）

每个redis结点，在启动时都会自动生成一个随机ID，每次启动都不一样，由40个随机的十六进制字符组成；runid用来唯一识别一个redis结点，通过info server命令，可以查看结点的runid

主从结点第一次复制时，主节点将自己的runid发送给从结点，从结点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：

* 如果从结点保存的runid与主节点现在的runid相同，说明从结点之前就同步过，主节点会继续尝试使用部分复制（到低能不能部分复制还要看offset和复制积压缓冲区的情况）
* 如果从结点保存的runid与主节点现在的runid不同，说明从结点在断线前同步的Redis结点并不是当前的主节点，只能进行全量复制

#### psync命令的执行

首先根据从结点的状态，决定如何调用psync命令：

* 如果从结点之前从未执行过slaveof或最近执行了slaveof no one，则从结点发送的命令为psync ？ -1，向主节点请求全量复制
* 如果从结点之前执行了slaveof命令，则发送命令为psync \<runid> \<offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从结点保存的赋值偏移量。

主节点根据接收到psync命令，以及当前服务器状态，决定执行全量复制还是部分复制：

* 如果主节点不支持psync，返回-err，然后从结点重新发送sync命令进行全量复制
* 如果支持psync，且runid和从结点发送的runid相同，并且从结点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+continue，表示进行部分复制，从结点等待主节点发送其缺少的数据即可
* 如果支持psync，但是runid不一样或者从根节点发送的offset之后的数据不在复制积压缓冲区中，回复+fullresync \<runid> \<offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从结点会保存这两个值

## 命令传播（复制）阶段

### 心跳机制

进入命令传播阶段后，master和slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线

master心跳：

* 使用指令ping
* 周期：由参数repl-ping-slave-period决定，默认10秒
* 作用：判断slave是否在线
* 查询：使用info replication命令可以查看这个信息

slave心跳任务：

* 指令：replconf ack {offset}
* 周期：1秒
* 作用：汇报slave自己的赋值偏移量，获取最新的数据变更指令；判断master是否在线

心跳阶段的注意事项：

当slave多数掉线，或者延迟过高时，master为保障数据稳定性，将拒绝所有信息同步操作

```shell
min-slaves-to-write 2
min-slaves-max-lag 8
```

slave数量小于2个，或者所有slave的延迟都大于等于10秒时，强制关闭master写功能，停止数据同步

slave数量和延迟由slave发送replconf ack命令确认

### 过程

1. 每隔指定时间，主节点会向从结点发送ping命令
2. 每隔1秒，从结点会向主节点发送replconf ack命令，命令格式为REPLCONF ACK {offset}，其中offset表示从结点保存的复制偏移量。
3. 主节点接收到命令，检查offset是否在缓冲区中，
   * 如果不在缓冲区，执行全量复制
   * 如果在缓冲区，offset和主节点offset相同，忽略
   * 如果在缓冲区，offset和主节点offset不相同，发送+continue offset
4. 从结点收到+continue，保存master的offset，执行bgrewriteaof，恢复和主节点相差的数据

# 哨兵模式

sentinel（哨岗，哨兵）是Redis的高可用解决方案：由一个或者多个Sentinel实例组成的Sentinel系统可以监控任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。

当主服务器的下线时长超过了指定的时长上限之后，Sentinel系统就会对主服务器执行故障转移操纵：

* 首先，Sentinel系统会挑选主服务器属下的其中一个服务器，并将这个被选中的从服务器升级为新的主服务器
* 然后，Sentinel系统会向主服务器属下的所有从服务器发送新的复制指令，让他们成为新的主服务器的从服务器，当所有从服务器都开始复制新的主服务器时，故障转移操作执行完毕
* 另外，Sentinel还会继续监视已经下线的主服务器，并在他重新上线时，将他设置为新的主服务器的从服务器

## 启动并初始化Sentinel

启动一个Sentinel可以使用命令：

```shell
redis-sentinel /path/to/your/sentinel.conf 或者
redis-server /path/to/your/sentinel.conf --sentinel
```

当启动一个Sentinel时，他需要执行以下步骤：

1. 初始化服务器
2. 将普通Redis服务器使用的代码替换为Sentinel专用代码
3. 初始化Sentinel状态
4. 根据给定的配置文件，初始化Sentinel的监视器主服务器列表
5. 创建连向主服务器的网络连接

### 初始化主服务器

Sentinel本质上是一个特殊模式下的Redis服务器，因此Sentinel服务器的初始化和普通Redis服务器的初始化并不完全相同，例如普通服务器初始化通过加载AOF或者RDB来还原数据库状态，但是Sentinel并不用加载

### 使用Sentinel专用代码

这一步就是将一部分普通Redis服务器使用的代码替换为Sentinel专用代码。

例如：

* 普通redis使用的端口常量REDIS_SERVERPORT被替换为REDIS_SENTINEL_PORT常量，值为26379
* 普通redis使用redisCommandTable作为服务器的命令表，Sentinel使用sentinelcmds作为命令表

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220212208848.png" alt="image-20220220212208848" style="zoom: 50%;" />

### 初始化sentinel状态

在应用了Sentinel的专用代码之后，接下来，服务器会初始化一个sentinelState结构（Sentinel状态），这个结构保存了服务器中所有和Sentinel功能有关的状态（服务器的一般状态仍然由redisServer结构保存）

### 初始化Sentinel状态的masters属性 

Sentinel状态中的masters字典中记录了所有被Sentinel监视的主服务器的相关信息，其中：

* 字典的键是被监视的主服务器的名字
* 字典的值是被监视主服务器对应的sentinelRedisInstance结构

每个sentinelRedisInstance结构（实例结构）代表一个被Sentinel监视的Redis服务器实例（instance），这个实例可以是主服务器，从服务器，或者另一个Sentinel

### 创建连接主服务的网络连接

创建网络连接后，Sentinel将成为主服务器的客户端，它可以向主服务器发送命令，并从命令的回复中获取相关信息

对每一个被Sentinel监视的主服务器来说，Sentinel会创建两个连接主服务器的异步网络连接：

* 一个是命令连接，这个连接专门用于向主服务器发送命令，并接收命令回复
* 另一个是订阅连接，这个连接专门用于订阅主服务器的 \__sentinel__:hello频道。 

## 获取主服务器信息

Sentinel默认会以十秒一次的频率，通过命令连接向被监视的主服务器发送Info命令，并通过分析Info命令的恢复来获取主服务器的当前信息。

通过分析主服务器的info命令恢复，Sentinel会得到以下信息：

* 主服务器本身的信息：

  * run_id服务器运行id，
  * role域记录的服务器角色

* 主服务器属下所有从服务器的信息

  * IP域记录从服务器的IP地址

  * port域记录从服务器的端口号

    根据这些IP地址和端口号，Sentinel不用用户提供从服务器的地址信息，就可以自动发现从服务器

## 获取从服务器信息

当Sentinel发现主服务器有新的从服务器出现时，Sentinel除了会为这个新的从服务器创建相应的实例结构之外，Sentinel还会创建连接到从服务器的命令连接和订阅连接。

在创建命令连接之后，Sentinel在默认情况下，会以十秒一次的频率通过命令连接向从服务器发送Info命令，并可以从答复中获取如下信息：

* 从服务器的运行Id，runid
* 从服务器的角色role
* 主服务器的IP地址master_host，以及主服务器的端口号master_port
* 主服务器的连接状态master_links_status
* 从服务器的优先级slave_priority，可以在故障恢复中使用
* 从服务器的复制偏移量slave_repl_offset，可以在故障恢复中使用

## 向主服务器和从服务器发送信息

在默认情况下，Sentinel会以两秒一次的频率，通过命令连接向所有被监控的主服务器和从服务器发送以下格式的命令：

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220223905634.png" alt="image-20220220223905634" style="zoom:80%;" />

这条命令向服务器的\_sentinel_:hello频道发送了一条消息，消息的内容如下：

* Sentinel本身的信息
  * Sentinel的IP地址
  * 端口号
  * 运行ID
  * Sentinel当前的配置纪元（configuration epoch）

* 主服务器的信息
  * 主服务器名字
  * IP地址
  * 端口号
  * 主服务器当前的配置纪元

## 接收来自主服务器和从服务器的频道信息

当Sentinel与一个主服务器或从服务器建立起订阅连接之后，Sentinel就会通过订阅连接，向服务器发送以下命令：`subscribe _sentinel_:hello`，这个命令用来订阅\_sentinel_:hello频道

sentinel对\_sentinel_:hello频道的订阅会一直持续到Sentinel与服务器的连接断开为止

这也就是说，对于每一个与Sentinel连接的服务器，Sentinel既通过命令连接向服务器的\_sentinel_:hello频道发送信息，又通过订阅连接从服务器的\_sentinel_:hello频道接收消息。

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220224926317.png" alt="image-20220220224926317" style="zoom:80%;" />

对于监视同一个服务器的Sentinel来说，一个Sentinel发送的信息会被其他Sentinel接收到，这些信息会被用于更新其他Sentinel对发送信息的Sentinel的认知，也会被用于更新其他Sentinel对被监视服务器的认知

当一个Sentinel从\_sentinel_:hello频道接收到一条消息之后，Sentinel会对其中的消息进行提取分析：

* 如果消息中的Sentinel运行ID和自己的一样，那么这条消息是自己发送的，Sentinel会丢弃这条消息
* 如果不一样，那么说明这条消息是监视同一个服务器的其他Sentinel发送过来的，接收消息的Sentinel将根据消息中的各个参数，对相应主服务器的实例结构进行更新

当Sentinel通过频道信息发现一个新的Sentinel时，它不仅会为新的Sentinel在sentinels字典中创建相应的实例结构，还会创建一个连向新Sentinel的命令连接，而新Sentinel也同样会创建连向这个Sentinel的命令连接，最终监视同一个主服务器的多个Sentinel将形成互相连接的网络。使用这种命令连接相连的各个Sentinel可以通过向其他Sentinel发送命令请求来进行信息交换。

## 检测主观下线状态

在默认情况下，Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器，从服务器，其他Sentinel在内）发送ping命令，并通过实例返回的ping命令回复来判断实例是否在线

实例对ping命令的回复可以分为一下两种情况：

* 有效回复：实例返回+pong，-loading，-masterdown三种回复中的一种
* 无效回复：除了以上三种回复，或者在指定时间内没有回复

Sentinel配置文件中的down-after-millisends选项指定了Sentinel判断实例进入主观下线所需要的时间长度：

* 如果一个实例在down-after-millisends毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的flags属性打开sri_s_down标识，用来表示这个实例已经进入主管下线状态

用来判断是否主观下线状态的这个时长可以用到主，从服务器以及其他sentinel上，并且每个sentinel的这个时长可能不同

## 检查客观下线状态

当Sentinel将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他Sentinel进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。当Sentinel从其他Sentinel那里接收到足够数量的已下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器执行故障转移操作。

一个Sentinel判断客观下线的过程：

1. 源Sentinel发送sentinel is-master-down-by-addr命令，询问其他sentinel是否同意主服务器已经下线，命令中参数如下：
   * IP，判断是否下线的主服务器IP
   * port，主服务器端口
   * current_epoch，Sentinel当前纪元，用于选举领头Sentinel
   * Sentinel的运行ID
2. 其他Sentinel接收SENTINEL is-master-down-by-addr命令，会解析各个参数，同时检查主服务器是否已经下线，然后向源Sentinel返回一条包含三个参数的Multi Bulk回复作为SENTINEL is-master-down-by-addr命令的回复，回复内容如下：
   * down_state，检查结果，1代表已经下线，0代表没有下线
   * leader_runid，目标Sentinel的局部领头Sentinel的运行ID，或者是*
   * leader_epoch，目标Sentinel的局部领头Sentinel的配置纪元，用于选举领头Sentinel
3. 源Sentinel接收SENTINEL is-master-down-by-addr命令的回复 ，根据其他Sentinel发回的回复，Sentinel将统计其他Sentinel同意主服务器已经下线的数量，当这个数量达到配置文件中配置的参数quorum（`sentinel monitor master IP地址 端口号 quorum`）时，Sentinel会将主服务器实例结构flags属性的SRI_O_DOWN标识打开，表示主服务器已经进入客观下线状态。

## 选取领头Sentinel

当一个主服务器被判断为客观下线时，监视这个下线主服务器的各 个Sentinel会进行协商，选举出一个领头Sentinel，并由领头Sentinel对下线主服务器执行故障转移操作。

选取领头Sentinel的规则：

* 所有监视主服务器的在线的Sentinel都有可能称为领头Sentinel
* 每次进行领头Sentinel选举后，不论选举是否成功，所有Sentinel的配置纪元的值都会自增一次，配置纪元实际上就是一个计数器
* 在一个配置纪元里面（相当于是一轮选举之中），所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会，并且局部领头一旦设置成功，在这轮选举中就不能再更改
* 每一个发现主服务器进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel
* 当一个源Sentinel向另一个目标Sentinel发送sentinel is-master-down-by-addr命令，并且命令中的runid不是*，而是自己的运行ID，这表示源Sentinel要求目标Sentinel将自己设置为后者的局部领头Sentinel
  * Sentinel设置局部领头Sentinel的规则是先到先得，之后接收到的所有设置要求都会被拒绝
  * 目标Sentinel在接收到sentinel is-master-down-by-addr命令之后，会向源Sentinel返回一条回复，回复中的leader_runid参数和leader_epoch参数记录了目标Sentinel局部领头Sentinel的运行ID和配置纪元
  * 源Sentinel在接收到目标Sentinel返回的命令回复之后，会检查回复中的配置纪元是否和自己相同，然后在检查领头id是否和自己相同，如果一直，就说明自己被设置为局部领头Sentinel
  * 如果某个Sentinel被半数以上的Sentinel设置为局部领头Sentinel，那么这个Sentinel将成为领头Sentinel

* 如果给定时间内，没有一个Sentinel被选举为领头Sentinel，那么各个Sentinel将在一段时间后继续进行选举，直到选出领头Sentinel

## 故障转移

在选举产生领头Sentinel后，领头Sentinel将对已经下线的主服务器执行故障转移操作，该操作包含一下三个步骤

1. 在已下线主服务器属下的所用从服务器里面，挑选出一个服务器，并将其转换为主服务器
2. 让已下线主服务器属下的所有从服务器改为复制新的主服务器
3. 将已下线主服务器设置为新的主服务器的从服务器，这个旧服务器从新上线时，它就会成为新的主服务器的从服务器

### 选出新的主服务器

领头Sentinel会将已下线主服务器的所有从服务器保存到一个列表里面，然后按照一下规则，一项一项的对列表进行过滤：

* 删除列表中已经下线或者断线装填的从服务器
* 删除列表中所有最近五秒乜有回复过领头Sentinel的Info命令的从服务器
* 删除和主服务器连接断开超过down-after-milliseconds*10毫秒的从服务器
* 根据优先级排序，选取优先级最高的
* 如果优先级一样，将所有从服务器的复制偏移量（offset）排序，选取最大的
* 如果都一样，按照运行ID排序，选取运行ID最小的

### 修改从服务器的复制目标

当新的主服务器出现之后，领头Sentinel下一步要做的就是让已经下线主服务器属下的所有从服务器去复制新的主服务器，这一动作可以通过向从服务器发送slaveof命令来实现

### 将旧的主服务器变为从服务器

故障转移操作最后要做的就是将已经下线的主服务器设置为新的主服务器的从服务器，

但是因为旧的主服务器已经下线，所以这种设置是保存在这个服务器对应的实例结构里面，当这个服务器重新上限时，Sentinel就会向他发送slaveof命令，让它称为新的主服务器的从服务器。



# 企业级解决方案

## 缓存预热

在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的**缓存预热**，后台更新缓存的机制刚好也适合干这个事情。

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220320103046125.png" alt="image-20220320103046125" style="zoom:67%;" />

## 缓存雪崩

通常，我们为了保证缓存中的数据与数据库中的数据一致性，会给Redis里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存中，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到Redis中，这样后续请求都可以直接命中缓存。

那么当大量缓存数据在同一时间过期（失效）或者Redis故障宕机，如果此时有大量的用户请求，都无法在Redis中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是**缓存雪崩**的问题。

**因此发生缓存雪崩的原因有两个：**

* 大量数据同时过期
* Redis故障宕机

不同的雪崩原因，对应的策略也会有所不同：

大量数据同时过期：

* 永久key+人工维护
* 构建多级缓存
* 均匀设置过期时间：如果要给缓存数据设置过期时间，应该避免将大量数据设置为同一过期时间，我们可以在对缓存设置过期时间的时候，给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。
* 设置互斥锁，如果发现用户请求的数据不在缓存中，那么就加个互斥锁，保证同一时间只有一个请求在构建缓存（从数据库中读数据，再将数据更新到Redis中），当缓存构建完成之后，再去释放锁。

Redis故障宕机：

* 服务熔断或者请求限流机制
* 构建Redis缓存高可靠集群



## 缓存击穿

缓存中的某个**热点key过期**，但是这一时间大量请求热点key的请求进来，都没有命中，然后访问数据库。

缓存击穿和缓存雪崩很相似，可以看做是缓存雪崩的一个子集。

因此可以使用解决缓存雪崩的方式来解决缓存击穿问题：

* 热点key永不过期
* 互斥锁方案

## 缓存穿透

缓存穿透说简单点就是⼤量请求的 key 根本**不存在于缓存中，**导致请求直接到了数据库上，根本没有经过缓存这⼀层。

发生缓存穿透的情况：

* 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库都没有数据。
* 黑客恶意攻击，

应对缓存穿透的方案：

* 非法请求的限制，在API入口处，我们就判断请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果为否，那么就直接返回错误 。
* 缓存空值或者默认值，当我们发现缓存穿透的现象时，就可以在缓存针对查询数据，缓存一个空值或者默认值，这样后续的请求就可以从缓存中的读取到，而不会去查询数据库。
* 使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。

### 布隆过滤器

布隆过滤器通过三个操作在bitmap上完成标记：

1. 使用N个哈希函数分别对数据做哈希计算，得到N个哈希值
2. 将第一步得到的N个哈希值对位图的长度取模，得到每个哈希值在位图上对应的位置
3. 将每个哈希值在位图数组上对应的位置设置为1。

布隆过滤器说数据存在，那么数据不一定存在；布隆过滤器说数据不存在，那么数据一定不存在。







