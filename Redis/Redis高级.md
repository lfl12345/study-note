![image-20220218212548787](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220218212548787.png)

# 数据结构

## SDS简单动态字符串

Redis中没有使用C语言的字符串（使用\0作为结尾的字符），而是自己构建了一种名为简单动态字符串（simple dynamic string，SDS）的抽象结构，SDS是Redis的默认字符串表示。

在redis中，包含字符串的键值对在底层都是使用SDS实现的。除了字符串值之外，SDS还被用作缓冲区：AOF中的AOF缓冲区，客户端状态的输入缓冲区，都是SDS实现的。

### SDS的定义

Redis针对不同长度的字符串，定义了不同的sdshdr结构体，最基本的结构体内容如下：

* len：已使用字节长度，即字符串长度。Redis中限制字符串最大长度不能超过512M
* alloc：已申请的字节长度，即sds总长
* flag：低3位表示sdshdr类型，高5位表示字符串长度
* buf：字符串内容，

sds遵循C语言字符串结尾习惯，使用空字符结尾，并且不计入len，alloc的计算，这样的话，sds可以直接使用C语言中的一些函数。

### SDS和C字符串的区别

C语言使用长度为N+1的字符数组来表示长度为N的字符串，并且字符数组的最后一个元素总是空字符'\0'。 

#### 常数复杂度获取字符串长度

C字符串并不记录字符串的信息，如果想要获取字符串的长度，必须遍历整个字符串，然后计数。

而SDS中记录了字符串的长度len，可以将获取字符串长度的复杂度降到常数级别，从而使得获取字符串长度不会影响Redis的性能。

#### 杜绝缓冲区溢出

由于C语言字符串不记录字符串长度信息，如果另个字符串进行拼接的话，容易造成内存溢出。

但是SDS的内存分配策略杜绝了发生内存溢出的可能性：

* 当对sds进行修改时，会先检查sds的空间是否满足修改要求，如果不满足，自动将sds的空间扩容为原来的两倍，但是有一个最大值，然后再进行实际的修改操作。

#### 减少修改字符串带来的内存分配次数

因为C语言字符串长度和底层数组的长度之间存在着相等的关系，因此对于C语言的字符串的每次增长或缩短都对应着一次内存的重新分配，这样性能是不高的。

为了避免C语言的这种缺陷，redis通过未使用空间解除了字符串长度和底层数组长度之间的关联：在sds中，buf数组的长度不一定就是字符串长度加一，数组中可以包含没有使用的字节，而这些字节的数量就是alloc-len的值。

**空间预分配**

空间预分配用于优化sds字符串增长的操作：当sds的api对一个sds进行修改，并且需要对sds进行空间扩展的时候，程序不仅会为sds分配修改所需要的空间，还会为sds分配额外的未使用的空间。

* 如果修改后sds长度小于1MB，那么程序分配的值是len值的两倍
* 如果修改后sds长度大于1MB，那么程序会分配1MB的free空间

**惰性内存释放**

惰性内存释放用于优化sds字符串缩短操作：当sds的api需要缩短sds保存的字符串时，程序并不立即使用内存重分配来后手缩短后多出来的字节，而是使用alloc和len属性的差值将这些字节记录起来，并等待将来使用。

#### 二进制安全

C字符串中的字符必须符合某种编码，并且除了字符串的末尾外，不能有空字符，要不就会被当做结尾处理，这限制了C字符串只能保存文本类的信息。

redis为了确保sds可以适用于各种不同的保存场景，sds的api都是二进制安全的，所有sds的api都会以处理二进制的方式来处理sds存放在buf数组中的数据，程序不会对其中的数据做任何限制，过滤，或者其他操作，数据在写入的时候什么样，出来的时候就是什么样。

这也就是我们将buf属性称为字节数组的原因，redis不是用这个数组来保存字符，而是用来保存一系列二进制数据。

#### 兼容部分C字符串

因为sds最后一个字符遵循C字符的规范，是一个空字符，因此如果sds中保存的是纯文本的话，可以使用C中关于字符串的函数，这样就不用重写函数，例如：比较函数，追加字符串的函数

#### 总结

![image-20220218112642303](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220218112642303.png)

## 链表list

### 链表和链表结点的实现

每个链表结点使用一个listNode结构来实现：

```C
typedef struct listNode { 
    // 前置节点
    struct listNode * prev; 
    // 后置节点
    struct listNode * next; 
    // 节点的值
    void * value; 
}listNode;
```

保存链表信息的结构体：

```C
typedef struct list { 
    // 表头节点
    listNode * head;
    // 表尾节点
    listNode * tail; 
    // 链表所包含的节点数量 
    unsigned long len; 
    // 节点值复制函数 
    void *(*dup)(void *ptr); 
    // 节点值释放函数 
    void (*free)(void *ptr); 
    // 节点值对比函数 
    int (*match)(void *ptr,void *key); 
} list;
```

### ziplist

Redis内部使用该链表保存运行时的数据，如主服务下所有的从服务器信息。但是Redis并不使用该链表保存用户列表数据，因为它对内存管理不够友好：

* 链表中的每个结点都使用独立的一块内存，导致内存碎片过多
* 链表结点中前后结点指针占用过多的额外空间

因此，Redis使用ziplist来保存用户列表数据，ziplist是一种类似于数组的紧凑链表格式，他会申请一整块内存，在这个内存上放该链表所有的数据，这就是ziplist的设计思想

ziplist总体布局如下：

zlbytes+zltail+zllen+entry+entry+...+entry+zlend

* zlbytes记录整个ziplist占用的字节数，包括zlbytes占用的4字节
* zltail记录从ziplist起始位置到最后一个字节的偏移量，用于支持链表从尾部弹出或反向遍历
* zllen记录结点数量，两字节，如果超过最大值，需要使用遍历获取结点数量
* zlend特殊的标志结点，等于255，表示结尾
* entry就是ziplist中保存的结点

entry的布局如下：

prevlen+encoding+entry-data

* entry-data结点存储的数据
* prevlen：记录前驱结点长度，这个属性长度为1字节或5字节
  * 如果前驱长度下小于254，使用1个字节
  * 否则，使用5个字节，第一个字节固定254，剩下4字节存储前驱结点长度
* encoding，表示当前结点元素的编码格式，包含编码类型和节点长度

### quicklist

虽然ziplist可以解决list的内存问题，但是他也有缺点：

* 因为存储紧凑，所以新增元素时，需要扩展内存，并将之前的数据拷贝过来
* 如果内容过多，内存分配和元素拷贝就会消耗很大，因此它不适合存储大量数据

quicklist的设计思想很简单，讲一个长ziplist拆分为多个端ziplist，避免插入或删除元素时导致大量的内容拷贝。

多个ziplist使用双向链表串联起来，每个ziplist的大小为8K



## 字典hash

Redis数据库就是使用字典作为底层实现的；字典也是哈希键的底层实现之一。当一 个哈希键包含的键值对比较多，又或者键值对中的元素都是比较长的字 符串时，Redis就会使用字典作为哈希键的底层实现。

### 字典的实现

字典中的键值对定义如下：

```C
typedef struct dictEntry {
    // 键 
    void *key; 
    // 值 
    union{
        void *val; 
        uint64_tu64; 
        int64_ts64; 
    } v; 
    // 指向下个哈希表节点，形成链表 
    struct dictEntry *next; 
} dictEntry;
```

字典中Hash表的定义如下：

```C
typedef struct dictht { 
    // 哈希表数组 ,负责存储数据
    dictEntry **table; 
    // 哈希表大小 
    unsigned long size; 
    // 哈希表大小掩码，用于计算索引值 
    // 总是等于size-1 
    unsigned long sizemask; 
    // 该哈希表已有节点的数量 
    unsigned long used; 
} dictht;
```

Redis中的字典定义如下：

```C
typedef struct dict { 
    // 指定操作数据的函数指针 
    dictType *type; 
    // 私有数据
    void *privdata; 
    // 定义两个hash表用于字典扩容机制，通常情况下只会使用ht[0],扩容时会创建ht[1]，并在操作数据时逐步将ht[0]的数据移到ht[1]中
    dictht ht[2]; 
    // rehash 索引 
    // 当rehash 不在进行时，值为-1 
    long rehashidx; /* rehashing not in progress if rehashidx == -1 */ 
    // 当前运行的迭代器数量，迭代器用于遍历字典键值对
    unsigned long iterators;
} dict;
```

dictType定义了字典中用于操作数据的函数指针，这些函数负责实现数据复制，比较等操作。

```C
typedef struct dictType { 
    // 计算哈希值的函数 
    unsigned int (*hashFunction)(const void *key); 
    // 复制键的函数 
    void *(*keyDup)(void *privdata, const void *key); 
    // 复制值的函数 
    void *(*valDup)(void *privdata, const void *obj); 
    // 对比键的函数 
    int (*keyCompare)(void *privdata, const void *key1, const void *key2); 
    // 销毁键的函数 
    void (*keyDestructor)(void *privdata, void *key); 
    // 销毁值的函数 
    void (*valDestructor)(void *privdata, void *obj); } dictType;
```

通过dictType指定操作数据的函数指针，字典就可以存放不同类型的数据了，但是在一个字典中，键，值可以是不同的类型，但是键必须类型相同，值也必须类型相同。

### 哈希算法

使用SIPHash算法，该算法能有效的放置Hash表碰撞攻击，并提供不错的性能

然后通过&运算来计算index，因此redishash表的大小应该也是2的整数倍

### 解决哈希冲突

Redis的哈希表使用链地址法（separate chaining）来解决键冲突，使用头插的方式

### 扩容

Redis使用一种**渐进式扩容方式**，这样设计，是因为Redis是单线程的，如果在一个操作将ht[0]所有数据都迁移到ht[1]，那么可能会引起线程长期阻塞。所以Redis字典扩容是在每次操作数据时都执行一次扩容单步操作，扩容操作即将ht[0].table[rehashidx]的数据迁移到ht[1]。等到ht[0]的所有数据都迁移到ht[1]，便将ht[0]指向ht[1]，完成扩容。

redis扩容后的大小是大于现在存储的键值对的2倍的最小的2的整数幂次方

hash表在一下情况下回执行扩容操作：

* hash存储的键值对大于等于hash数组的长度，也就是负载因子（等于 已经保存结点数量/哈希表大小）大于等于1、
* 负载因子大于dict_force_resize_ratio

当负载因子小于0.1时，redis对哈希表进行缩容

### 渐进式扩容

为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1]，而是分多次、渐进式地将ht[0]里面的键值对慢慢地rehash到ht[1]。

1. 为1分配空间，字典同时具有0，1两个表
2. 在字典中维护rehashindex，将它的值设为0，表示rehash开始
3. rehash期间，每次对字典执行添加，删除，查找，或者更新操作时，程序除了执行指定的操作之外，还会顺带将0表在rehashidx索引上的所有键值对rehash到ht1中，当rehash工作完成之后，程序将rehashrdx属性的值加一
4. 当ht0全部被移到ht1之后，程序将rehashidx设置为-1，表示rehash操作已经完成

**渐进式rehash期间执行的哈希表操作**

在rehash过程中，字典的增删改查会在两个哈希表中进行，查找的话先查找ht0，再查找ht1；

添加操作全部加到ht1中，

## 跳跃表

跳跃表是一种有序数据结构，它通过在每个结点中维持多个指向其他结点的指针，从而达到快速访问结点的目的。

跳跃表支持平均O(logN)，最坏O(N)复杂度的结点查找，还可以通过顺序性操作来批量处理结点

在大部分情况下，跳跃表的效率可以和平和树相媲美，并且因为跳跃表的实现比平衡树更为简单，主要体现在插入和删除结点之后的维护上，所以有不少程序都使用跳跃表来代替平衡树。

Redis使用跳跃表作为有序集合键（Zset）底层实现之一（实际是hash字典+跳跃表），如果一个有序集合包含的元素数量比较多，又或者有序集合元素的成员是比较长的字符串时，Redis就会使用跳跃表来作为有序集合的底层实现。

Redis只在两个地方使用到了跳跃表：实现有序集合，集群结点中用作内部数据结构。

### 跳跃表的实现

zskiplist结构用于保存跳跃表结点的相关信息：

```C
typedef struct zskiplist { 
    // 表头节点和表尾节点 
    struct zskiplistNode *header, *tail; 
    // 表中节点的数量 
    unsigned long length; 
    // 表中层数最大的节点的层数 ，最大为32层
    int level; 
} zskiplist;
```

zskiplistNode 用于表示跳跃表结点：

```C
typedef struct zskiplistNode { 
    // 结点值
    sds ele;
    // 分数，用于排序结点
    double score; 
    // 层级
    struct zskiplistLevel { 
        // 后驱结点 
        struct zskiplistNode *forward; 
        // 本层的后继结点跨过第一层多少结点，用于计算节点索引
        unsigned long span; 
    } level[]; 
    // 指向前驱结点，一个结点只有第一层有前驱结点，因此skiplist的第一层是一个双向链表
    struct zskiplistNode *backward; 
} zskiplistNode;
```

### 插入操作

## 整数集合

整数集合intset是集合键（set）的底层实现之一。当一个集合值包含整数元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现。

### 整数集合的实现

```C
typedef struct intset { 
    // 编码方式
    uint32_t encoding; 
    // 集合包含的元素数量 
    uint32_t length; 
    // 保存元素的数组 
    int8_t contents[]; 
} intset;
```

存储的各个项在contents中从小到大排序，并且不包含重复的内容

### 升级

每当我们要将一个新元素添加到整数集合里面时，并且新元素的类型比整数集合现在所有元素的类型都要长时，整数集合需要先进行升级，然后才能将新元素添加到整数集合里面。

升级步骤：

1. 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间
2. 将底层数组的元素都转换成和新元素相同的类型，并将类型转换后的元素放置到正确位置上，而且在放置元素的过程中，需要继续维持底层数组的有序性不变。
3. 将新元素添加到底层数组里面。

所以向整数集合添加 新元素的时间复杂度为O（N）。 

整数集合不支持降级操作

### 升级的好处

1. 提升灵活性
2. 节约内存



## 压缩列表ziplist



















# 数据库

## 服务器中的数据库

Redis服务器将所有数据库都保存在服务器状态redisServer结构的db数组中，db数组的每个项都是一个redisDb结构，每个redisDb结构代表一个数据库：

初始化服务器时，程序会根据服务器状态的dbnum属性来决定创建多少个数据库。dbnum有配置文件中的database配置项决定，默认16

```C
struct redisServer { 
    // ... 
    // 一个数组，保存着服务器中的所有数据库 
    redisDb *db; 
    //服务器的数据库数量 
    int dbnum;
    // ... 
};
```

## 切换数据库

每个客户端都会有一个目标数据库，客户端状态redisClient结构的db属性记录了客户端当前的目标数据库，这个属性是一个执行redisDb结构的指针：

```C
typedef struct redisClient {
	// ... 
    //记录客户端当前正在使用的数据库 
    redisDb *db; 
    // ... 
} redisClient;
```

通过改变redisClient中的属性db指向不同的数据库来实现改变客户端操作的数据库。

## 数据库的键空间

表示数据库的结构体redisDb中的属性dict，他表示了一个字典，用于保存这个数据库所有的键值对

```C
typedef struct redisDb { 
    // ... 
    // 数据库键空间，保存着数据库中的所有键值对 
    dict *dict; 
    // ... 
} redisDb;
```



# 持久化

持久化的方式：

* 将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注数据本身
* 将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在操作过程

RDB就是第一种持久化的方式，AOF是第二种持久化的方式，Redis都有支持。

## RDB

### RDB持久化方式—save

客户端使用命令`save`可以使用RDB方式持久化数据。

手动的执行一次保存操作

save指令的相关配置：

```shell
dbfilename dump.rdb #设置保存的文件名，默认为dump.rdb,一般设置为dump-port.rdb
dir # 设置存储.rdb文件的目录
rdbcompression yes # 设置存储时是否压缩数据，默认yes
rdbchecksum yes # 是否进行RDB文件格式校验，该校验在写文件和读文件过程都会进行
```

### RDB持久化方式—bgsave

因为Redis是单线程的，如果数据库数据较多，save指令会造成进程阻塞，直到RDB文件创建完毕为止，因此会造成数据库效率降低。

因此我们可以使用bgsave指令使redis的持久化操作在后台执行。

调用bgsave指令之后，redis会fork出来一个子进程，然后子进程执行持久化数据库的任务，最后将结果写入日志文件中。主进程不会阻塞，直接返回。

除了前面提到的四个配置之外，bgsave还有一个配置参数：

```shell
stop-writes-on-bgsave-error yes # 后台持久化过程中如果遇到错误是否停止操作，默认yes
```

在bgsave执行期间，save和bgsave指令都会被回绝

同时bgrewriteaof和bgsave两个指令不能同时执行，虽然他俩没啥联系，但是同时启动两个执行大量IO的子进程不是什么好主意，性能会下降。

### RDB持久方式—自动执行

但是使用客户端输入指令的方式执行持久化操作有很多弊端，例如：不知道何时要执行操作，不知道之前是否执行过操作等。

我们可以通过配置文件进行配置，使满足指定条件的情况下redis自动进行持久化操作。

配置方式：

```shell
save second changes
```

说明：满足限定时间（second）内key的变化数量达到指定数量（changes）即进行持久化

save配置要根据实际业务情况进行设置，频度过高或过低都会出现性能问题，结果可能是灾难性的 

### RDB的载入工作

RDB文件的载入工作是在服务器启动时自动执行的，所以Redis并没有专门用于载入RDB文件的命令，只要Redis服务器在启动时检测到RDB文件存在，它就会自动载入RDB文件。

但是因为AOF文件的更新频率通常比RDB文件的更新频率高，所以，如果服务器开启了AOF持久功能，那么服务器会优先使用AOF文件来还原数据库状态，只有在AOF持久功能处于关闭状态时，服务器才会使用RDB文件来还原数据库状态。

### 优缺点

优点:

* RDB是一个紧凑压缩的二进制文件，存储效率高
* 内部存储的是redis在某个时间点的数据快照，非常适合用于数据备份，全量复制等场景
* rdb恢复数据的速度比AOF要快很多
* 应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复

缺点：

* RDB方式无论使用那种方式进行持久化，都无法做到实时持久化，具有较大的可能性丢失数据
* bgsave执行每次运行都要fork子进程，要牺牲一些性能
* Redis众多版本中未进行RDB文件格式的版本统一，有可能出现个版本服务器之间数据格式无法兼容现象

## AOF

RDB的弊端：

* 存储数据量较大，效率较低，基于快照思想，每次读写都是全部数据，当数据量巨大时，效率非常低
* 大数据量下的IO性能较低
* 基于fork创建子进程，内存产生额外消耗
* 宕机带来的数据丢失风险

### AOF概念

AOF（append only file）持久化：以独立日志的方式记录每次写命令，重启时在重新执行AOF文件中命令达到恢复数据的目的。与RDB相比可以简单描述为改变记录数据为记录数据产生的过程

AOF的主要作用是解决了数据持久化的实时性，目前已经是redis持久化的主流方式

可以使用一下配置打开AOF功能：

```shell
appendonly yes|no # 是否开启AOF功能 默认为不开启
appendfsync always|everysec|no # AOF写数据的策略
appendfilename filename # AOF持久化文件名，默认文件名未appendonly.aof，建议配置为appendonly-端口号.aof
dir # AOF持久化保持文件的目录
```

aof写数据的策略：

* always：每次写入操作都同步到AOF文件中，数据零误差，性能较低
* everysec：每秒将缓冲区中的指令同步到AOF文件中，数据准确性高，性能高
* no：由操作系统控制每次同步到AOF文件的周期，整体过程不可控

### AOF持久化的实现

AOF持久化功能的实现可以分为命令追加（append），文件写入，文件同步（sync）三个步骤。

#### 命令追加

当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾。

#### AOF文件的写入与同步

AOF文件的写入就是在每次事件循环结束之后，Redis会调用flushAppendOnlyFile函数，考虑是否将缓冲区的内容写入和保存到AOF文件中去。

flushAppendOnlyFile函数的行为由服务器的配置appendfsync选项值来决定（这个值默认为everysec）：

![image-20220219102555858](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220219102555858.png)

### AOF文件的载入和数据还原

Redis读取AOF并还原数据库状态的详细步骤：

1. 打开AOF文件
2. 创建一个不带网络的伪客户端，用于执行AOF文件中的命令。因为Redis中的命令只能在客户端上下文中执行。
3. 从AOF中读取并解析一条命令
4. 使用伪客户端执行被读出来的写命令
5. 重复3和4

### AOF重写

Redis4提供了AOF混合持久化，通过aof-use-rdb-preamble配置进行控制，默认为yes，代表启用，配置为no则可以禁用。

开启AOF混合持久化后，AOF重写时，会将Redis数据以RDB格式保存到新文件（生成文件更小，加载速度更快），再将重写缓冲区的增量命令以AOF格式写入文件。

关闭AOF混合持久化后，AOF重写时，则将Redis所有数据转换为写入命令写入新文件。

AOF重写过程可以分为3步骤：

1. fork一个子进程，称为AOF进程，AOF进程负责将当前内存数据保存到一个新文件中
2. AOF进程将步骤1执行期间主进程执行的增量命令（这些命令保存在重写缓冲区）写入到新文件中，最后结束AOF进程
3. 主进程进行收尾工作，将步骤2执行期间主进程执行的增量命令也写入新文件中，
4. 原子替换AOF文件，AOF重写完成

## RDB和AOF对比

![image-20220219104045010](C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220219104045010.png)

# Redis事务

redis的事务提供了一种将多个命令请求打包，然后一次性，按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而该去执行其他客户端的命令，他会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令。

但是redis不支持回滚，如果事务中有命令执行失败了，那么redis会继续执行后续命令而不是回滚。

## 事务的基本操作

开启事务：multi，设置事务的开启位置，此指令执行后，后续所有指令均会加入到事务中

执行事务：exec，设置事务的结束位置，同时执行事务，与multi成对出现，成对使用

加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行exec命令才开始执行

**如果在事务定义的过程中出现了问题怎么办？**

取消事务：discard，终止当前事务，发生在multi之后，exec之前

**事务注意事项：**

* 定义事务的过程中，命令格式输入错误：
  * 整体事务中所有命令均不会执行。包括那些语法正确的命令。
* 命令格式正确，但是语法错误，无法执行 
  * 能正确运行的命令会运行，运行错误的命令不会运行，不会回滚

## 事务的实现

一个事务从开始到结束会经历三个阶段：事务开始，命令入队，事务执行

### 事务开始

multi命令标志着事务的开始，

multi命令可以将执行该命令的客户端从非事务状态切换为事务状态，这一切换是通过在客户端状态的flags属性中打开REDIS_MULTI标识来完成的。

### 命令入队

当一个客户端处于非事务状态时，这个客户端发送的命令会立即被服务器执行。

但是，当一个客户端处于事务状态时，服务器会根据客户端发来的不同命令执行不同的操作：

* 如果是exec，discard，watch，multi命令中的一个，那么服务器会立即执行这个命令。
* 如果不是，将命令放入一个事务队列中，然后返回queued回复。

### 事务队列

每个Redis客户端都有自己的事务状态，这个事务状态保存在客户端状态的mstate属性中，

事务状态包含一个事务队列，以及一个入队命令的计数器（也可以说是事务队列的长度）

事务队列以先进先出（FIFO）的方式	保存入队命令，

### 执行事务

当一个处于事务状态的客户端向服务器发送EXEC命令时，这个EXEC命令将立即被服务器执行，服务器会遍历这个客户端的事务队列，执行队列中保存的所有命令，最后将执行命令的结果全部返回给客户端。

## watch命令的实现

watch命令是一个乐观锁，它可以在exec命令执行之前，监视任意数量的数据库键，并在exec命令执行时，检查被监视的键是否至少有一个已经被修改过了，如果是的话，服务器将拒绝执行事务，并向客户端返回代表事务执行失败的空恢复。

可以使用unwatch命令取消对所有key的监视。

**使用watch监视数据库键**

每个Redis数据库（redisDb结构体）都保存一个watched_keys字典，该字典的键是数据库中被监视的Redis键，字典的值是监视字典键的所有客户端链表。

**监视机制的触发**

对所有数据库进行修改的命令，在执行之后都会调用touchWatchKey函数对watched_keys字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键，

* 如果有，那么touchWatchKey函数会将监视被修改键的客户端的Redis_dirty_cas标识打开，表示客户端的事务安全性被破坏

**判断事务是否安全**

当服务器接收到一个客户端发来的**exec命令**时，服务器会根据这个客户端是否打开了redis_dirty_cas标识来决定是否执行事务：

* 如果客户端的redis_dirty_cas标识已经被打开，那么说明客户端所监视的键中，至少一个键已经被修改，那么客户端提交的事务已经不安全，所以服务器拒绝执行客户端提交的事务
* 如果客户端的redis_dirty_cas标识没有被打开，事务是安全的，服务器将执行客户端提交的这个事务。



# 分布式锁

使用setnx设置一个公共锁，

```shell
setnx lock-key value
```

利用setnx命令的返回值特性，有值则返回设置失败，没有值则返回设置成功

* 对于返回设置成功的，代表获取到了锁，可以执行下一步操作
* 对于返回设置失败的，不具有控制权，排队或者等待

当获取到锁的线程完成操作之后，通过del操作释放锁

## 分布式锁改良

依赖setnx的分布式锁机制，如果客户端获取到锁之后宕机，那么锁就不会释放，因此我们必须给这个锁设置一个超时时间，当客户端获取到这个锁一段时间之后，如果超时，那么锁将自动释放。

使用expire或者pexpire命令进行设置超时时间的任务。

这个超时时间的选择可以通过大量的测试，也就是可以看看每次获取到锁的线程在执行多长时间后就会释放锁，根据大量的实验，可以取一个最大值作为锁的超时时间。

# Redis的删除策略

Redis可以挺过ttl命令获取对应key在内存中的状态：

* xx：还有xx剩余时间就过期的数据
* -1：永久有效的数据
* -2：已经过期的数据 或者 被删除的数据 或者 从未存在过的数据

但是Redis中已经过期的数据不一定被真正删除了，因为考虑到CPU的使用率和性能原因，由于删除操作并不太重要，因此可以暂缓删除操作，让它在以后CPU空闲的时候在删除。具体怎么删除，需要看使用的什么删除策略

## 设置键的过期时间

Redis有四种不同的命令设置键的过期时间：expire，pexprie，expireat，pexpireat，虽然有四种，但是实际上expire，pexprie，expireat三个命令都是使用pexpire命令来实现的：无论客户端执行的是以上四个命令中的那一个，经过转换之后，最终执行效果都和pexpireat命令一样，最终都会调用同一个方法。

### 保存过期时间

redisDb的expires字典中保存了数据库中所有键的过期时间，我们称这个字典为过期字典：

* 过期字典的键是一个指针（地址），这个指针指向键空间中的某个键对象（也就是某个数据库键）
* 过期字典的值是一个long long类型的整数，这个整数保存了键所指向的数据库键的过期时间——一个毫秒精度的UNIX时间戳

```C
typedef struct redisDb { 
    // ... 
    // 过期字典，保存着键的过期时间
	dict *expires; 
    // ... 
} redisDb;
```

当客户端执行设置过期时间的四个命令时，服务器会在数据库的过期字典（expires）中关联给定的数据库键和过期时间

### 移除过期时间

persist命令可以移除一个键的过期时间，persist命令就是pexpireat命令的反操作：persist命令在过期字典中查找给定的键，并解除和键（过期时间）在过期字典中的关联

### 过期时间的判定

1. 检查给定键是否存在于过期字典：如果存在，那么取得键的过期时间
2. 检查当前UNIX时间戳是否大于键的过期时间：如果是的话，那么键已经过期；否则的话，键未过期

## 数据删除策略

要设计这种删除策略的原因：在内存占用和CPU占用之间寻找一种平衡，顾此失彼都会造成整体redis性能的下降，甚至引发服务器宕机或内存泄漏

### 定时删除

创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作

优点：节约内存，到时就删除，快速释放掉不必要的内存占用

缺点：

* CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量

* 除此之外，创建一个定时器需要用到Redis服务器中的时间事件，而当前时间事件的实现方式—无序链表，查找一个事件的时间复杂度为O(N)—并不能高效地处理大量时间事件

总结：用处理器性能换区存储空间

### 惰性删除

数据到达过期时间，不做处理，等下次访问该数据时：

* 如果未过期，返回数据
* 发现已经过期，删除，返回不存在

优点：节约CPU性能，发现必须删除的时候才删除

缺点：内存压力很大，出现长期占用内存的数据

总结：用存储空间换处理器性能（拿空间换时间）

### 定期删除

以上两种方案是两种极端，可以使用一种折中的方案

周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度。并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响

特点：

* CPU性能占用设置有峰值，检测频度可自定义设置
* 内存压力不是很大，长期占用内存的冷数据会被持续清理

总结：周期性抽查存储空间（随机抽查，重点抽查）

## 删除策略的实现

Redis服务器中实际使用的是惰性删除和定期删除两种策略：

### 惰性删除的实现

当用户查询键时，检测键是否过期，如果键已经过期，则删除该键。这个操作是由expireIfNeeded函数完成的。

### 定期删除的实现

* 服务启动时读取server.hz参数配置的值
* 每秒钟执行server.hz次serverCron函数，然后这个函数会调用activeExpireCycle函数
* activeExpireCycle函数对每个数据库的过期字典（expires）逐一进行检查，函数每次执行固定的时间250ms/server.hz
* 对每个过期字典检查时，随机挑选W个key进行检查
  * 如果key超时，删除key
  * 如果这一轮中删除的key的数量大于W*25%，循环该过程
  * 如果这一轮中删除的key的数量小于W*25%，检查下一个expires
  * W取值=active_expire_cycle_lookups_per_loop属性值
* 参数current_db用于记录activeExpireCycle进入到那个库的expires执行
* 如果activeExpireCycle执行时间到期，下次从current_db继续向下执行

## 数据淘汰机制

当新数据进入redis时，如果内存不够用怎么办？此时就需要使用数据淘汰机制将内存中的数据删除一部分用来缓存新的数据。

在redis执行每一个命令之前，都会调用freeMemoryIfNeeded函数检测内存是否充足，如果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。

影响数据逐出的相关配置：

```shell
maxmemory # 最大可用内存，占用物理内存的比例，默认0，表示不限制
maxmemory-samples # 每次选取待删除数据的个数，选取数据时并不会全库扫描，导致严重性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据
maxmemory-policy # 删除策略，达到最大内存后，对被选出来的数据进行删除的策略
```

Redis支持一下数据逐出算法：

* 检测会过期的数据（expires数据字典中的数据）
  * volatile-lru：挑选最近最少使用的数据淘汰
  * volatile-lfu：挑选最近使用次数最少的数据淘汰
  * volatile-ttl：挑选将要过期的数据淘汰
  * volatile-random：任意选择数据淘汰
* 检测全库数据（所有数据，在dict数据字典上的数据）
  * allkeys-lru：挑选最近最少使用的数据淘汰
  * allkeys-lfu：挑选最近使用次数最少的数据淘汰
  * allkeys-random：任意选择数据淘汰
* 放弃数据淘汰
  * no-eviction(驱逐)：禁止驱逐数据（redis4中的默认策略）

通常使用双向链表实现LRU算法，但是由于使用链表记录所有键的访问顺序需要耗费过多内存，所以Redis并没有采用这种方式。

Redis使用的是LRU近似算法，从数据中获取部分随机数据作为样本数据，并将样本数据中最合适的数据淘汰。LFU算法那同样使用类似的近似算法。

为了实现LRU和LFU近似计算，Redis使用redisObject.lru记录键的最新访问时间（LRU时间戳）或键的访问频率（LFU计数），每次查找键都会更新redisObject.lru属性

如果使用LFU，则调用updateLFU函数更新LFU计数

# 主从复制

主从复制机制的作用：

* 数据冗余，将数据热备份到从结点，即使主节点由于磁盘损坏丢失数据，从结点依然保留数据副本
* 读写分离，可以有主节点提供写服务，从结点提供读服务，Redis服务整体吞吐量
* 故障恢复，主节点故障下线后，可以手动将从结点切换为主节点，继续提供服务
* 高可用基础，主从复制是Sentinel和Cluster机制的基础，Sentinel和Cluster都实现了故障转移，即主节点故障停止后，Redis负责选择一个从结点切换为主节点，继续提供服务

主从复制的流程可以分为三个阶段：

1. 握手阶段：主从连接成功后，从结点需要将自身信息（IP，端口）发送给主节点，以便主节点能认识自己

2. 同步阶段：从结点连接主节点后，需要先同步数据，数据达到一致（或者只有最新的变更不一致）后才进入复制阶段

   Redis支持两种同步机制

   * 全量同步：从结点发送psync ？ -1，要求进行全量同步，主节点返回响应+fullresync，表示同意全量同步。随后，主节点生成RDB数据并发送给从结点，这种方式常用于新的从结点首次同步数据
   * 部分同步：从结点发送命令psync replid offset，要求进行部分同步，主节点相应+continue，表示同意部分同步。主节点只需要把复制积压区中offset偏移量之后的命令发送给从结点即可（主节点会将执行的写命令都写入复制积压区）。这种方式常用于主从连接断开重连时同步数据。如果offset不在复制积压区中，那么主节点也会返回+fullresync，要求进行全量复制

3. 复制阶段：主节点在运行期间，将执行的写命令传播给从结点，从结点接收并执行这些命令，从而达到复制数据的效果。Redis使用的是异步复制，主节点传播命令后，并不会等待从结点返回ack确认，异步复制的优点是低延时和高性能，缺点是可能在短期内主从结点数据不一致

## 主从握手流程

1. 从结点设置主服务器的地址和端口。当客户端给从服务器发送replicaof masterip masterport命令或者从服务器配置文件中有配置replicaof masterip masterport，从服务器就将主服务器的地址和端口保存到服务器状态的masterhost和masterport属性中。

2. 从结点使用replicaofCommand函数处理replicaof命令，

   1. 如果处理的命令时replicaof no one，则将当前服务器专换为主节点，取消原来的主从复制关系，退出函数
   2. 调用replicationsetmaster函数，与给定服务器建立主从关系，这个函数会断开从结点之前的主从关系，断开从结点的从结点，将从结点的状态变为正在连接状态

   当从结点server.repl_state进入**repl_state_connect**正在连接状态后，**主从复制流程已已经开始**

3. serverCorn时间事件负责对**repl_state_connect**状态进行处理，如果服务器处于正在连接状态，那么会调用**connectWithMaster**函数进行处理，这个函数负责建立主从网络连接。

   当socket连接成功之后，从服务器为这个套接字关联一个专门用于处理复制工作的文件事件处理器，这个处理器负责执行后续的复制工作。

   主服务器将该套接字创建相应的客户端状态，并将从服务器看做是一个连接到主服务器的客户端来看待

4. 网络连接成功后，从结点调用用**syncWithMaster**函数，进入握手阶段。

5. 从结点发送ping命令，进入repl_state_reveive_pong状态。

   * 通过ping命令可以检查套接字的读写状态
   * 检查服务器是否能正确处理命令请求

   > ping命令的回复情况
   >
   > 1. 主服务器回复超时，从服务器断开并重新创建连向主服务器的套接字。 
   > 2. 主服务器返回错误，从服务器断开并重新创建连向主服务器的套接字。 
   > 3. 主服务器返回pong，从服务器可以继续执行复制工作的下个 步骤

6. 从服务器接收到pong返回之后，进入repl_state_send_auth状态。如果从服务器开启了主从认证，那么发送auth命令以及认证密码，进入repl_state_receive_auth状态；如果从服务器没有开启主从认证，直接进入repl_state_send_port状态。

   > 在认证阶段，主服务器设置了不同的密码，或者主服务器设置了密码，从服务器没有设置，或者主服务器没有设置，从服务器设置了，都会造成从服务器断开并重新创建向主服务器的套接字或者不再连接

7. 身份验证之后，进入repl_state_send_port状态，从服务器发送自己的端口信息给主节点。从服务器执行命令replconf listening-port \<port-number>，向主服务器发送从服务器的监听端口号。进入repl_state_receive_port状态

8. 读取相应没问题之后，从结点进入repl_state_send_ip状态，发送从结点IP地址给主节点，然后进入repl_state_receive_ip状态

9. 读取响应没问题之后，从结点进入repl_state_send_capa状态，发送capa信息，进入repl_state_receive_capa状态

   > capa全称为capabilities，代表从结点支持的复制能力

10. 读取响应没问题之后，从结点进入repl_state_send_psync状态，发送psync命令到主节点，发起同步流程，进入repl_state_receive_psync状态

执行到这里，主从握手阶段已经完成，server.repl_state必须处于repl_state_receive_psync状态，否则报错

## 同步阶段

一下的同步步骤假设从服务器是第一次连接主服务器

### 全量复制

1. 因为从服务器的cached_master不存在（在从服务器中的主节点缓存），因此使用全量复制，从服务器发送psync ？ -1命令
2. 主服务器收到从服务器第一次发送的全量复制的指令后，将该客户端添加到server.slaves中，此时如果主节点的复制积压区没创建，创建复制积压区
3. 主节点生成一个RDB文件，并发送到从结点
4. 此时从结点接收到主节点的返回信心
   1. 如果主节点不支持psync，那么重新发送sync命令
5. 从结点清除旧数据，载入接收到的RDB文件
6. 主节点将生成RDB文件以及发送过程中又接收到的指令（这些指令以AOF的形式存在复制缓冲区中）
7. 从结点接收到这些同步信息后，先执行bgrewriteaof，然后将数据同步

### 部分复制

由于全量复制在主节点数据量较大的时候效率很低，因此redis还支持了部分复制，主要用于解决在断网一段时间后的主从数据同步问题。

#### 复制偏移量

主节点和从节点分别维护一个复制偏移量（offset），代表的是**主节点向从节点传递的字节数**；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。

offset可以用来判断主从数据库的一致性：

* 如果两者offset相同，则一致
* 如果offset不同，则不一致，如果复制积压缓冲区中还存在着这个offset之后的数据，此时可以根据两个offset找出从节点缺少的那部分数据。

#### 复制积压缓冲区

复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区

在命令传播阶段，主节点除了将命令发送给从结点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还村粗了其中的么个字节对应的复制偏移量（offset）。由于复制积压缓冲区是定长且是先进先出，所以它保存的是主节点最近执行的写命令，时间较早的命令会被挤出缓冲区。

由于缓冲区长度固定，因此可以备份的写命令业有限，当主从结点offset的差距过大 超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。

从结点将offset发送给主节点之后，主节点会更具offset决定是否执行部分复制：

* 如果offset偏移量之后的数据，仍然在复制缓冲区中，则执行部分复制
* 如果offset偏移量之后的数据已经不在复制积压缓冲区中，则执行全量复制

#### 服务器运行ID（runid）

每个redis结点，在启动时都会自动生成一个随机ID，每次启动都不一样，由40个随机的十六进制字符组成；runid用来唯一识别一个redis结点，通过info server命令，可以查看结点的runid

主从结点第一次复制时，主节点将自己的runid发送给从结点，从结点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：

* 如果从结点保存的runid与主节点现在的runid相同，说明从结点之前就同步过，主节点会继续尝试使用部分复制（到低能不能部分复制还要看offset和复制积压缓冲区的情况）
* 如果从结点保存的runid与主节点现在的runid不同，说明从结点在断线前同步的Redis结点并不是当前的主节点，只能进行全量复制

#### psync命令的执行

首先根据从结点的状态，决定如何调用psync命令：

* 如果从结点之前从未执行过slaveof或最近执行了slaveof no one，则从结点发送的命令为psync ？ -1，向主节点请求全量复制
* 如果从结点之前执行了slaveof命令，则发送命令为psync \<runid> \<offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从结点保存的赋值偏移量。

主节点根据接收到psync命令，以及当前服务器状态，决定执行全量复制还是部分复制：

* 如果主节点不支持psync，返回-err，然后从结点重新发送sync命令进行全量复制
* 如果支持psync，且runid和从结点发送的runid相同，并且从结点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+continue，表示进行部分复制，从结点等待主节点发送其缺少的数据即可
* 如果支持psync，但是runid不一样或者从根节点发送的offset之后的数据不在复制积压缓冲区中，回复+fullresync \<runid> \<offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从结点会保存这两个值

## 命令传播（复制）阶段

### 心跳机制

进入命令传播阶段后，master和slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线

master心跳：

* 使用指令ping
* 周期：由参数repl-ping-slave-period决定，默认10秒
* 作用：判断slave是否在线
* 查询：使用info replication命令可以查看这个信息

slave心跳任务：

* 指令：replconf ack {offset}
* 周期：1秒
* 作用：汇报slave自己的赋值偏移量，获取最新的数据变更指令；判断master是否在线

心跳阶段的注意事项：

当slave多数掉线，或者延迟过高时，master为保障数据稳定性，将拒绝所有信息同步操作

```shell
min-slaves-to-write 2
min-slaves-max-lag 8
```

slave数量小于2个，或者所有slave的延迟都大于等于10秒时，强制关闭master写功能，停止数据同步

slave数量和延迟由slave发送replconf ack命令确认

### 过程

1. 每隔指定时间，主节点会向从结点发送ping命令
2. 每隔1秒，从结点会向主节点发送replconf ack命令，命令格式为REPLCONF ACK {offset}，其中offset表示从结点保存的复制偏移量。
3. 主节点接收到命令，检查offset是否在缓冲区中，
   * 如果不在缓冲区，执行全量复制
   * 如果在缓冲区，offset和主节点offset相同，忽略
   * 如果在缓冲区，offset和主节点offset不相同，发送+continue offset
4. 从结点收到+continue，保存master的offset，执行bgrewriteaof，恢复和主节点相差的数据

# 哨兵模式

sentinel（哨岗，哨兵）是Redis的高可用解决方案：由一个或者多个Sentinel实例组成的Sentinel系统可以监控任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。

当主服务器的下线时长超过了指定的时长上限之后，Sentinel系统就会对主服务器执行故障转移操纵：

* 首先，Sentinel系统会挑选主服务器属下的其中一个服务器，并将这个被选中的从服务器升级为新的主服务器
* 然后，Sentinel系统会向主服务器属下的所有从服务器发送新的复制指令，让他们成为新的主服务器的从服务器，当所有从服务器都开始复制新的主服务器时，故障转移操作执行完毕
* 另外，Sentinel还会继续监视已经下线的主服务器，并在他重新上线时，将他设置为新的主服务器的从服务器

## 启动并初始化Sentinel

启动一个Sentinel可以使用命令：

```shell
redis-sentinel /path/to/your/sentinel.conf 或者
redis-server /path/to/your/sentinel.conf --sentinel
```

当启动一个Sentinel时，他需要执行以下步骤：

1. 初始化服务器
2. 将普通Redis服务器使用的代码替换为Sentinel专用代码
3. 初始化Sentinel状态
4. 根据给定的配置文件，初始化Sentinel的监视器主服务器列表
5. 创建连向主服务器的网络连接

### 初始化主服务器

Sentinel本质上是一个特殊模式下的Redis服务器，因此Sentinel服务器的初始化和普通Redis服务器的初始化并不完全相同，例如普通服务器初始化通过加载AOF或者RDB来还原数据库状态，但是Sentinel并不用加载

### 使用Sentinel专用代码

这一步就是将一部分普通Redis服务器使用的代码替换为Sentinel专用代码。

例如：

* 普通redis使用的端口常量REDIS_SERVERPORT被替换为REDIS_SENTINEL_PORT常量，值为26379
* 普通redis使用redisCommandTable作为服务器的命令表，Sentinel使用sentinelcmds作为命令表

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220212208848.png" alt="image-20220220212208848" style="zoom: 50%;" />

### 初始化sentinel状态

在应用了Sentinel的专用代码之后，接下来，服务器会初始化一个sentinelState结构（Sentinel状态），这个结构保存了服务器中所有和Sentinel功能有关的状态（服务器的一般状态仍然由redisServer结构保存）

### 初始化Sentinel状态的masters属性 

Sentinel状态中的masters字典中记录了所有被Sentinel监视的主服务器的相关信息，其中：

* 字典的键是被监视的主服务器的名字
* 字典的值是被监视主服务器对应的sentinelRedisInstance结构

每个sentinelRedisInstance结构（实例结构）代表一个被Sentinel监视的Redis服务器实例（instance），这个实例可以是主服务器，从服务器，或者另一个Sentinel

### 创建连接主服务的网络连接

创建网络连接后，Sentinel将成为主服务器的客户端，它可以向主服务器发送命令，并从命令的回复中获取相关信息

对每一个被Sentinel监视的主服务器来说，Sentinel会创建两个连接主服务器的异步网络连接：

* 一个是命令连接，这个连接专门用于向主服务器发送命令，并接收命令回复
* 另一个是订阅连接，这个连接专门用于订阅主服务器的 \__sentinel__:hello频道。 

## 获取主服务器信息

Sentinel默认会以十秒一次的频率，通过命令连接向被监视的主服务器发送Info命令，并通过分析Info命令的恢复来获取主服务器的当前信息。

通过分析主服务器的info命令恢复，Sentinel会得到以下信息：

* 主服务器本身的信息：

  * run_id服务器运行id，
  * role域记录的服务器角色

* 主服务器属下所有从服务器的信息

  * IP域记录从服务器的IP地址

  * port域记录从服务器的端口号

    根据这些IP地址和端口号，Sentinel不用用户提供从服务器的地址信息，就可以自动发现从服务器

## 获取从服务器信息

当Sentinel发现主服务器有新的从服务器出现时，Sentinel除了会为这个新的从服务器创建相应的实例结构之外，Sentinel还会创建连接到从服务器的命令连接和订阅连接。

在创建命令连接之后，Sentinel在默认情况下，会以十秒一次的频率通过命令连接向从服务器发送Info命令，并可以从答复中获取如下信息：

* 从服务器的运行Id，runid
* 从服务器的角色role
* 主服务器的IP地址master_host，以及主服务器的端口号master_port
* 主服务器的连接状态master_links_status
* 从服务器的优先级slave_priority，可以在故障恢复中使用
* 从服务器的复制偏移量slave_repl_offset，可以在故障恢复中使用

## 向主服务器和从服务器发送信息

在默认情况下，Sentinel会以两秒一次的频率，通过命令连接向所有被监控的主服务器和从服务器发送以下格式的命令：

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220223905634.png" alt="image-20220220223905634" style="zoom:80%;" />

这条命令向服务器的\_sentinel_:hello频道发送了一条消息，消息的内容如下：

* Sentinel本身的信息
  * Sentinel的IP地址
  * 端口号
  * 运行ID
  * Sentinel当前的配置纪元（configuration epoch）

* 主服务器的信息
  * 主服务器名字
  * IP地址
  * 端口号
  * 主服务器当前的配置纪元

## 接收来自主服务器和从服务器的频道信息

当Sentinel与一个主服务器或从服务器建立起订阅连接之后，Sentinel就会通过订阅连接，向服务器发送以下命令：`subscribe _sentinel_:hello`，这个命令用来订阅\_sentinel_:hello频道

sentinel对\_sentinel_:hello频道的订阅会一直持续到Sentinel与服务器的连接断开为止

这也就是说，对于每一个与Sentinel连接的服务器，Sentinel既通过命令连接向服务器的\_sentinel_:hello频道发送信息，又通过订阅连接从服务器的\_sentinel_:hello频道接收消息。

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220220224926317.png" alt="image-20220220224926317" style="zoom:80%;" />

对于监视同一个服务器的Sentinel来说，一个Sentinel发送的信息会被其他Sentinel接收到，这些信息会被用于更新其他Sentinel对发送信息的Sentinel的认知，也会被用于更新其他Sentinel对被监视服务器的认知

当一个Sentinel从\_sentinel_:hello频道接收到一条消息之后，Sentinel会对其中的消息进行提取分析：

* 如果消息中的Sentinel运行ID和自己的一样，那么这条消息是自己发送的，Sentinel会丢弃这条消息
* 如果不一样，那么说明这条消息是监视同一个服务器的其他Sentinel发送过来的，接收消息的Sentinel将根据消息中的各个参数，对相应主服务器的实例结构进行更新

当Sentinel通过频道信息发现一个新的Sentinel时，它不仅会为新的Sentinel在sentinels字典中创建相应的实例结构，还会创建一个连向新Sentinel的命令连接，而新Sentinel也同样会创建连向这个Sentinel的命令连接，最终监视同一个主服务器的多个Sentinel将形成互相连接的网络。使用这种命令连接相连的各个Sentinel可以通过向其他Sentinel发送命令请求来进行信息交换。

## 检测主观下线状态

在默认情况下，Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器，从服务器，其他Sentinel在内）发送ping命令，并通过实例返回的ping命令回复来判断实例是否在线

实例对ping命令的回复可以分为一下两种情况：

* 有效回复：实例返回+pong，-loading，-masterdown三种回复中的一种
* 无效回复：除了以上三种回复，或者在指定时间内没有回复

Sentinel配置文件中的down-after-millisends选项指定了Sentinel判断实例进入主观下线所需要的时间长度：

* 如果一个实例在down-after-millisends毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的flags属性打开sri_s_down标识，用来表示这个实例已经进入主管下线状态

用来判断是否主观下线状态的这个时长可以用到主，从服务器以及其他sentinel上，并且每个sentinel的这个时长可能不同

## 检查客观下线状态

当Sentinel将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他Sentinel进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。当Sentinel从其他Sentinel那里接收到足够数量的已下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器执行故障转移操作。

一个Sentinel判断客观下线的过程：

1. 源Sentinel发送sentinel is-master-down-by-addr命令，询问其他sentinel是否同意主服务器已经下线，命令中参数如下：
   * IP，判断是否下线的主服务器IP
   * port，主服务器端口
   * current_epoch，Sentinel当前纪元，用于选举领头Sentinel
   * Sentinel的运行ID
2. 其他Sentinel接收SENTINEL is-master-down-by-addr命令，会解析各个参数，同时检查主服务器是否已经下线，然后向源Sentinel返回一条包含三个参数的Multi Bulk回复作为SENTINEL is-master-down-by-addr命令的回复，回复内容如下：
   * down_state，检查结果，1代表已经下线，0代表没有下线
   * leader_runid，目标Sentinel的局部领头Sentinel的运行ID，或者是*
   * leader_epoch，目标Sentinel的局部领头Sentinel的配置纪元，用于选举领头Sentinel
3. 源Sentinel接收SENTINEL is-master-down-by-addr命令的回复 ，根据其他Sentinel发回的回复，Sentinel将统计其他Sentinel同意主服务器已经下线的数量，当这个数量达到配置文件中配置的参数quorum（`sentinel monitor master IP地址 端口号 quorum`）时，Sentinel会将主服务器实例结构flags属性的SRI_O_DOWN标识打开，表示主服务器已经进入客观下线状态。

## 选取领头Sentinel

当一个主服务器被判断为客观下线时，监视这个下线主服务器的各 个Sentinel会进行协商，选举出一个领头Sentinel，并由领头Sentinel对下线主服务器执行故障转移操作。

选取领头Sentinel的规则：

* 所有监视主服务器的在线的Sentinel都有可能称为领头Sentinel
* 每次进行领头Sentinel选举后，不论选举是否成功，所有Sentinel的配置纪元的值都会自增一次，配置纪元实际上就是一个计数器
* 在一个配置纪元里面（相当于是一轮选举之中），所有Sentinel都有一次将某个Sentinel设置为局部领头Sentinel的机会，并且局部领头一旦设置成功，在这轮选举中就不能再更改
* 每一个发现主服务器进入客观下线的Sentinel都会要求其他Sentinel将自己设置为局部领头Sentinel
* 当一个源Sentinel向另一个目标Sentinel发送sentinel is-master-down-by-addr命令，并且命令中的runid不是*，而是自己的运行ID，这表示源Sentinel要求目标Sentinel将自己设置为后者的局部领头Sentinel
  * Sentinel设置局部领头Sentinel的规则是先到先得，之后接收到的所有设置要求都会被拒绝
  * 目标Sentinel在接收到sentinel is-master-down-by-addr命令之后，会向源Sentinel返回一条回复，回复中的leader_runid参数和leader_epoch参数记录了目标Sentinel局部领头Sentinel的运行ID和配置纪元
  * 源Sentinel在接收到目标Sentinel返回的命令回复之后，会检查回复中的配置纪元是否和自己相同，然后在检查领头id是否和自己相同，如果一直，就说明自己被设置为局部领头Sentinel
  * 如果某个Sentinel被半数以上的Sentinel设置为局部领头Sentinel，那么这个Sentinel将成为领头Sentinel

* 如果给定时间内，没有一个Sentinel被选举为领头Sentinel，那么各个Sentinel将在一段时间后继续进行选举，直到选出领头Sentinel

## 故障转移

在选举产生领头Sentinel后，领头Sentinel将对已经下线的主服务器执行故障转移操作，该操作包含一下三个步骤

1. 在已下线主服务器属下的所用从服务器里面，挑选出一个服务器，并将其转换为主服务器
2. 让已下线主服务器属下的所有从服务器改为复制新的主服务器
3. 将已下线主服务器设置为新的主服务器的从服务器，这个旧服务器从新上线时，它就会成为新的主服务器的从服务器

### 选出新的主服务器

领头Sentinel会将已下线主服务器的所有从服务器保存到一个列表里面，然后按照一下规则，一项一项的对列表进行过滤：

* 删除列表中已经下线或者断线装填的从服务器
* 删除列表中所有最近五秒乜有回复过领头Sentinel的Info命令的从服务器
* 删除和主服务器连接断开超过down-after-milliseconds*10毫秒的从服务器
* 根据优先级排序，选取优先级最高的
* 如果优先级一样，将所有从服务器的复制偏移量（offset）排序，选取最大的
* 如果都一样，按照运行ID排序，选取运行ID最小的

### 修改从服务器的复制目标

当新的主服务器出现之后，领头Sentinel下一步要做的就是让已经下线主服务器属下的所有从服务器去复制新的主服务器，这一动作可以通过向从服务器发送slaveof命令来实现

### 将旧的主服务器变为从服务器

故障转移操作最后要做的就是将已经下线的主服务器设置为新的主服务器的从服务器，

但是因为旧的主服务器已经下线，所以这种设置是保存在这个服务器对应的实例结构里面，当这个服务器重新上限时，Sentinel就会向他发送slaveof命令，让它称为新的主服务器的从服务器。



# 企业级解决方案

## 缓存预热

## 缓存雪崩

缓存在同⼀时间⼤⾯积的失效，后⾯的请求都直接落到了数据库上，造成数据库短时间内承受⼤量请求。























































































