# 并发容器和框架

## ConcurrentHashMap

ConcurrentHashMap设计的目标是保持并发情况下的可读（get，迭代器等相关方法），同时尽量减少更新操作的竞争。

次要目标是保持空间消耗和HashMap大致相同或者更好，并支持多线程在空表上的高初始插入率。

在table上一共有4中类型的桶，Node，TreeBin，ForwardingNode和ReservationNode。在Node桶中，Node连接着一个链表，数据被封装成Node结点以链表的方式存储；在TreeBin桶中，TreeBin连接着一个红黑树，真实数据被封装成TreeNode结点以红黑树的结构存储，TreeBin指向红黑树的根节点。只有Node和TreeBin类型的桶中会存储真实的数据，其他两种类型的桶起辅助作用。

ForwardingNode是一种临时结点，hash值为固定值-1，在扩容进行中才会出现，相当于一个占位结点。当table数组的一个hash桶中全部的结点都迁移到了nextTable中，源table数组的桶中会被放置一个ForwardingNode结点。

ReservationNode是一个保留结点，hash值为固定值-3，在chm中就相当于一个占位符，不存储实际的数据，正常情况不会出现。在chm中，computeIfAbsent和compute这两个函数在加锁时会使用ReservationNode起到占位符的作用。

TreeBin是红黑树的顶级结点，hash值为固定值-2，当桶中的数据以红黑树结构存储的时候，TreeBin作为桶的顶级结点，存储在table中。

### 常量

```java
/**
 * 表的最大容量，因为32位散列字段的前两位用于控制目的，因此最大值必须只能是2的30次方。HashMap的最大容量也是2的30次方。
 */
private static final int MAXIMUM_CAPACITY = 1 << 30;

/**
 * 默认初始容量16
 */
private static final int DEFAULT_CAPACITY = 16;

/**
 * 最大的array的容量，在toArray或者相关的方法被调用的时候会用到，目前理解的意思是当我把chm转化为array的时候，此时这个array的最大的容量。
 */
static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

/**
 * 表的默认并发级别。未使用但为与此类的先前版本兼容而定义
 */
private static final int DEFAULT_CONCURRENCY_LEVEL = 16;

/**
 * 此表的负载因子，在构造函数中覆盖此值仅影响初始表容量，这个负载因子是一个final常量
 */
private static final float LOAD_FACTOR = 0.75f;

/**
 * 使用树而不是列表的 bin 计数阈值
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * 在调整大小操作期间 untreeifying（拆分）bin 的 bin 计数阈值。
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * 可以树化的最小的表容量
 */
static final int MIN_TREEIFY_CAPACITY = 64;

/**
 * Minimum number of rebinnings per transfer step. Ranges are
 * subdivided to allow multiple resizer threads.  This value
 * serves as a lower bound to avoid resizers encountering
 * excessive memory contention.  The value should be at least
 * DEFAULT_CAPACITY.
 */
private static final int MIN_TRANSFER_STRIDE = 16;

/**
 * The number of bits used for generation stamp in sizeCtl.
 * Must be at least 6 for 32bit arrays.
 */
private static int RESIZE_STAMP_BITS = 16;

/**
 * 帮助扩容的最大线程数量
 */
private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1;

/**
 * The bit shift for recording size stamp in sizeCtl.
 */
private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

/*
 * Encodings for Node hash fields. See above for explanation.
 */
static final int MOVED     = -1; // forwarding node的哈希值
static final int TREEBIN   = -2; // TreeNode的root结点TreeBin的哈希值
static final int RESERVED  = -3; // hash for transient reservations
static final int HASH_BITS = 0x7fffffff; // 30个1，正常hash值的掩码，屏蔽符号位
```

### Node内部类

Node类是chm中其他四个结点类的父类，TreeNode，ForwardingNode，ReservationNode，TreeBin。Node中定义了结点的hash值，key，value,以及next下一个结点的指针。

```java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    volatile V val;
    volatile Node<K,V> next;

    Node(int hash, K key, V val, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.val = val;
        this.next = next;
    }

    public final K getKey()       { return key; }
    public final V getValue()     { return val; }
    public final int hashCode()   { return key.hashCode() ^ val.hashCode(); }
    public final String toString(){ return key + "=" + val; }
    public final V setValue(V value) {
        throw new UnsupportedOperationException();
    }

    public final boolean equals(Object o) {
        Object k, v, u; Map.Entry<?,?> e;
        return ((o instanceof Map.Entry) &&
                (k = (e = (Map.Entry<?,?>)o).getKey()) != null &&
                (v = e.getValue()) != null &&
                (k == key || k.equals(key)) &&
                (v == (u = val) || v.equals(u)));
    }

    /**
     * Virtualized support for map.get(); overridden in subclasses.
     */
    Node<K,V> find(int h, Object k) {
        Node<K,V> e = this;
        if (k != null) {
            do {
                K ek;
                if (e.hash == h &&
                    ((ek = e.key) == k || (ek != null && k.equals(ek))))
                    return e;
            } while ((e = e.next) != null);
        }
        return null;
    }
}
```

### 静态方法（工具）

ConcurrentHashMap中没有hash方法，取而代之的是spread方法

```java
// usable bits of normal node hash，用来屏蔽符号位，使得正常结点的hash值都大于0
static final int HASH_BITS = 0x7fffffff; 
// 先对key的hash值的低16位进行扰动（使用高16位异或低16位），然后屏蔽符号位，结果为32位int型非负数	
static final int spread(int h) {
    return (h ^ (h >>> 16)) & HASH_BITS;
}
```

```java
// 将数组的大小变为大于c的最小的2的整数幂。这个方法的主要作用就是将传入的c最高位后面的位全部变为1，然后最后再加1，就是大于c的最小的2的整数幂
private static final int tableSizeFor(int c) {
    int n = c - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

### 获取table元素的方法

tabAt方法：获取table中索引位置index的最新值。tabAt方法通过Unsafe的getObjectVolatile方法获取table中index索引位置的值，等价于table[index]。

为什么使用getObjectVolatile而不直接使用table[index]来获取元素呢？

* 虽然table素组本身就是volatile变量，但是volatile类型的数组只针对数组的引用具有volatile可见性语义，而非它里面的元素，也就是如果使用table[index]来获取元素，有可能读取到的不是最新值，因此，处于安全考虑，使用getObjectVolatile以volatile读取方式读取table中元素的值，volatile关键字，可以保证可见性，这样就可以保证当前线程读取到的值都是当前的最新值。

```java
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}

static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                    Node<K,V> c, Node<K,V> v) {
    return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}

static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
    U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
}
```

### 字段

sizeCtl字段是非常重要的一个属性，sizeCtl的用途比较多，其中负数代表正在进行初始化或者扩容操作。根据情景的不同，sizeCtl有不同的含义以及作用，总结起来分为一下四种：

* 为0，默认值，表示数组没有初始化，同时table初始化时使用默认容量DEFAULT_CAPACITY
* 大于0，有两种含义
  * 如果数组未初始化，sizeCtl表示的是数组的初始容量，这种情况出现在使用非默认构造函数创建chm实例时。
  * 如果数组已经初始化，sizeCtl表示的是数组的扩容阈值（数组的初始容量*0.75，代码中使用位运算计算这个阈值），当chm中的键值对大于等于sizeCtl时，table会进行扩容迁移。

* 为-1，表示数组正在进行初始化table数组操作，初始化时使用方法initTable方法，使用CAS更新sizeCtl的值保证只有一个线程执行初始化操作。
* 小于0，并不是-1，表示数组正在扩容，-（1+nThreads），表示此时有nThreads个线程正在共同完成数组的扩容操作

```java
/**
 * 核心数组. 在第一次执行插入的时候懒惰初始化.
 * 大小永远是2的整数幂.
 */
transient volatile Node<K,V>[] table;

/**
 * 扩容时才会使用的一个临时数组，仅在扩容时非空
 */
private transient volatile Node<K,V>[] nextTable;

/**
 * ConcurrentHashMap元素总数的基本计数器, 主要在没有竞争的时候使用,
 * 但也可作为表初始化竞赛期间的后备
 * 通过CAS更新
 */
private transient volatile long baseCount;

/**
 * 表初始化或调整大小时候的控制.  如果为负数, 则表示正在初始化或者调整大小：-1表示初始化，
 * 否则-（1+调整大小线程的数量）。如果为非负数，当table为null时，表示的是要在创建时使用的初始表大小
 * 或者默认为0.初始化后，保存下一个元素计数值，根据该值调整表的大小
 */
private transient volatile int sizeCtl;

/**
 * resize的时候下一个需要处理的元素下标为index=transferIndex-1
 */
private transient volatile int transferIndex;

/**
 * resize或者创建CounterCells时的一个线程竞争标志位
 */
private transient volatile int cellsBusy;

/**
 * 计数单元表。当非空时，大小是 2 的幂。就相当于LongAdder中的cells
 */
private transient volatile CounterCell[] counterCells;
@sun.misc.Contended static final class CounterCell {
    volatile long value;
    CounterCell(long x) { value = x; }
}

// views
private transient KeySetView<K,V> keySet;
private transient ValuesView<K,V> values;
private transient EntrySetView<K,V> entrySet;
```

### 构造函数

建议在构造函数中给定初始容量，需要注意的是在CHM中如果给定的初始容量是32，那么构造出来的容量会是64，也就是大于给定的初始容量的最小的2的整数幂大小。

```java
public ConcurrentHashMap() {
}
// 通过给定的初始化容量来构造一个CHM
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}
public ConcurrentHashMap(Map<? extends K, ? extends V> m) {
    this.sizeCtl = DEFAULT_CAPACITY;
    putAll(m);
}
public ConcurrentHashMap(int initialCapacity, float loadFactor) {
    this(initialCapacity, loadFactor, 1);
}

public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (initialCapacity < concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long)(1.0 + (long)initialCapacity / loadFactor);
    int cap = (size >= (long)MAXIMUM_CAPACITY) ?
        MAXIMUM_CAPACITY : tableSizeFor((int)size);
    this.sizeCtl = cap;
}
```

### get方法

首先根据参数key的hash计算table的索引位置，也就是key值对应的桶的位置。查找元素情况，分为三种情况：

* table[index]上结点的key和待查找的key相等，直接返回结点对应的value
* table[index]上结点的hash值小于0，说明此位置不是Node结点，为TreeBin，ForwardingNode或者ReservationNode三种结点之一，这时可以通过对应结点的find方法查找匹配的结点，并返回结点的value。
* 如果前两中情况都不是，那么对应位置结点肯定是链表的头结点，则遍历链表，查找匹配的结点，并返回结点中的value。如果没有找到，最终返回null。

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode());
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

在上面的第二种情况中，我们通过三种非Node结点的find方法进行结点的查找，这三个结点都继承了Node结点并重写类find方法。三种结点的find方法的实现有所不同。

#### TreeBin的find方法

lockState是TreeBin中的一个属性，用来实现一个简单的读写锁。

```java
final Node<K,V> find(int h, Object k) {
    if (k != null) {
        for (Node<K,V> e = first; e != null; ) {
            int s; K ek;
            if (((s = lockState) & (WAITER|WRITER)) != 0) {
                if (e.hash == h &&
                    ((ek = e.key) == k || (ek != null && k.equals(ek))))
                    return e;
                e = e.next;
            }
            else if (U.compareAndSwapInt(this, LOCKSTATE, s,
                                         s + READER)) {
                TreeNode<K,V> r, p;
                try {
                    p = ((r = root) == null ? null :
                         r.findTreeNode(h, k, null));
                } finally {
                    Thread w;
                    if (U.getAndAddInt(this, LOCKSTATE, -READER) ==
                        (READER|WAITER) && (w = waiter) != null)
                        LockSupport.unpark(w);
                }
                return p;
            }
        }
    }
    return null;
}
```

#### ForwardingNode的find方法



### put方法

putVal方法的主要逻辑是：

* 首先将数据插入到对应索引的桶中
* 插入成功后，根据桶中结点的数量判断是否将链表转化为红黑树。
* 最后判断table数组是否需要扩容

putVal方法从代码逻辑上可以分为两个阶段：

* 第一个阶段：将数据插入table中
* 第二个阶段：更新chm的元素总数



#### putVal的第一阶段：插入数据

插入数据到table中，一共处理了一下四种情况：

1. table未初始化，先初始化table

   如果table为null，或者table长度为0，调用**initTable**方法对table进行初始化。由于线程处于一个自旋状态，等待table初始化完成后，还会重新执行插入操作。

2. table对应索引位置table[index]的桶是空的。

   如果对应位置为空，那么使用CAS将新创建的Node结点放入桶中。

   如果CAS成功，那么break掉循环，方法返回

   如果CAS失败，线程重新开始自旋执行插入操作。

3. table对应索引位置table[index]的桶不为空

   当table对应索引位置不为空时，可能有两种情况，索引位置是正常的Node，或者TreeBin结点，或者是ForwardingNode结点。此时如果判断桶位置的结点的hash值等于MOVED，那么说明桶位置的结点为ForwardingNode结点，表明table正在进行扩容 。

   那么当前线程会调用**helpTransfer**方法去帮助扩容。

   当帮助扩容完成之后，线程会重新开始自旋执行插入操作。

4. 如果不是以上四种情况，那么就说明table对应索引位置已经有了数据，出现了hash冲突，此时桶的类型分为两种情况：链表或者红黑树。

   1. 首先对桶位置table[index]加同步锁，加锁成功之后检验table[index]是否被修改，如果已经被修改，说明其他线程的写操作造成了table[index]中数据的变化，此时线程会自旋，重新进行插入操作

   2. 如果加锁成功后判断table[index]没有被修改，那么判断table[index]桶的类型是链表还是红黑树

      如果桶的类型是链表，首先遍历链表判断是否存在于插入数据相等的结点，如果存在，更新结点的值为新值，break掉循环；如果不存在，那么将数据添加到链表尾部。

      如果桶的类型是TreeBin，那么会将数据封装为TreeNode通过红黑树的方式进行插入。

      插入结束后，如果binCount（链表的长度）大于等于8，那么使用**treeifyBin**方法将链表转化为红黑树。

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}

final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 这个值一定是正数，方便后面添加元素判断该结点的类型
    int hash = spread(key.hashCode());
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        // f是链表的头结点
        // fh是链表头结点的hash
        // i是链表在table中的下标
        // n是table的长度
        Node<K,V> f; int n, i, fh;
        // 如果table为null或者table长度为0，创建table
        if (tab == null || (n = tab.length) == 0)
            // 初始化table使用的是CAS，不用上锁，创建成功后进入下一次循环
            tab = initTable();
        // 如果插入的key的hash对应table中的node为null
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 使用CAS添加node结点，break直接返回
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // 如果链表头结点的hash值等于MOVED
        else if ((fh = f.hash) == MOVED)
            // 帮忙扩容
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            // 锁住链表的头结点
            synchronized (f) {
                // 再次确认链表没有被移动，可能在阻塞获取锁的时候，链表被移动了
                if (tabAt(tab, i) == f) {
                    // 表示当前的结点是一个正常的结点
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 找到相同的key
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                // 更新旧的value
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            // 如果已经是最后一个节点了，新增一个结点
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    // fh等于-2的时候，表示是一个红黑树
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        // putTreeVal 会看 key 是否已经在树中, 是, 则返回对应的 TreeNode
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                              value)) != null) {
                            oldVal = p.val;
                            // 更新对应的value
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            // 释放链表头节点的锁
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    // 如果链表长度 >= 树化阈值(8), 进行链表转为红黑树
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

#### initTable方法

initTable用于初始化table数组，并返回初始化后的数组。

初始化table数组时用到了sizeCtl这个字段：

* sizeCtl为-1，代表数组正在初始化
* sizeCtl大于等于0，table未初始化，sizeCtl和初始化容量有关。table初始化后，sizeCtl为下次扩容阈值

initTable方法使用CAS无锁策略，保证同时只能有一个线程执行初始化table的工作。initTable方法主要逻辑如下：

* 检查table是否已经初始化过了，如果已经初始化了，那么直接退出方法，返回初始化后的table
* 如果没有初始化过，此时分为两种情况，table正在进行初始化，或者table还没有进行初始化
  * 如果发现sizeCtl小于0，那么当前线程主动让出CPU执行权，进入下一轮循环
  * 如果sizeCtl不小于0，那么使用CAS设置sizeCtl为-1，如果成功，那么当前线程对table进行初始化，同时将sizeCtl赋值为下一次扩容阈值（table的size*0.75）。

```java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) < 0)
            // 如果线程在初始化table的竞争中失败了，让出线程，然后在进行循环
            Thread.yield(); // lost initialization race; just spin
        // 尝试将 sizeCtl 设置为 -1（表示初始化 table）
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            // 获得锁, 创建 table, 这时其它线程会在 while() 循环中 yield 直至 table 创建
            try {
                if ((tab = table) == null || tab.length == 0) {
                    // 如果大于0，表示我们给了初始值，使用给定初始值初始化
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    // 计算下次扩容的大小，n*0.75，这里使用位运算实现
                    sc = n - (n >>> 2);
                }
            } finally {
                // 将下次扩容大小赋值给sizeCtl
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

#### treeifyBin方法

如果当前桶的链表长度大于等于8，但是table数组的总长度小于64，那么调用tryPresize对table进行扩容，而不是将链表转化为红黑树（处于性能考虑，减少哈希冲突和避免频繁的扩容迁移）。

如果当前桶的链表长度大于8，并且table数组的总长度大于64，那么将链表转化为红黑树。

* 首先对桶的头结点进行加锁，然后校验桶的头结点是否被更改，如果被修改，说明有其他线程修改了table[index]中数据，放弃转化，退出方法。
* 如果没有被修改，遍历单向Node链表，创建双向链表TreeNode链表。
* 最后根据TreeNode双向链表构建TreeBin并同时构建红黑树结构，将TreeBin更新到table[index]中。

由此可以看出，红黑树的TreeNode结点，事实上维护了两种数据结构：红黑树和双向链表。

```java
private final void treeifyBin(Node<K,V>[] tab, int index) {
    Node<K,V> b; int n, sc;
    if (tab != null) {
        // 如果数组的长度小于64，那么使用扩容操作来代替把链表转换为红黑树的操作
        if ((n = tab.length) < MIN_TREEIFY_CAPACITY)
            tryPresize(n << 1);
        else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {
            synchronized (b) {
                if (tabAt(tab, index) == b) {
                    TreeNode<K,V> hd = null, tl = null;
                    for (Node<K,V> e = b; e != null; e = e.next) {
                        TreeNode<K,V> p =
                            new TreeNode<K,V>(e.hash, e.key, e.val,
                                              null, null);
                        if ((p.prev = tl) == null)
                            hd = p;
                        else
                            tl.next = p;
                        tl = p;
                    }
                    setTabAt(tab, index, new TreeBin<K,V>(hd));
                }
            }
        }
    }
}
```

#### putVal的第二阶段：更新总数

addCount方法用来对chm中的键值对计数，chm的史书方式使用了分段锁的思想，当没有并发冲突时，直接使用baseCount计数，所有的计数都会记录在该变量上；当有并发冲突时，计算每个线程对应的索引位置，计数会被更新到counterCells数组对应的位置。

addCount这个方法做了两件事情：

1. 对table中的键值对进行计数
2. 如果table中键值对数量达到扩容阈值，进行扩容操作



维护集合长度：当counterCells不为null 或者 counterCells为null但是CAS添加BASECOUNT失败

* 如果counterCells为null 或者 counterCells长度为0，执行fullAddCount方法
* 如果counterCells不为null并且长度不为0，但是线程在counterCells中对应的cell为null，执行fullAddCount方法
* 如果counterCells不为null且长度不为0，同时线程在counterCells中对应的cell不为null，CAS设置线程对应的cell的value
  * 如果设置不成功，执行fullAddCount方法，同时传入的参数uncontended为false，其余的都是true
  * 如果设置成功，判断check参数，如果check参数小于等于1，直接返回；否则获取CHM中所有的元素个数

扩容处理：如果binCount（check）大于等于0

* 当集合中元素的个数大于等于扩容阈值sizeCtl 同时 集合不为空 并且table长度小于最大长度，循环扩容
  * 通过resizeStamp方法获取扩容戳（这个扩容戳的高16位全为0，第16位的第一位一定是1，并且后面不全为0，这样做的目的是让sizeCtl在扩容的时候是一个负数）
  * 如果sizeCtl小于零，此时表示已经有线程在进行扩容
    * 当sizeCtl转换为resizeStamp时不等于线程先前获取的resizeStamp，或者，sizeCtl已经等于resizeStamp+1,换句话说就是等于下一次扩容后的大小，或者，帮忙扩容的线程已经达到最大值，或者，nextTable等于null，或者，transferIndex小于等于0，break；
    * 如果CAS设置sizeCtl成功，此时上面的if不成立，说明还没有扩容完成，调用transfer方法帮助扩容；CAS失败，进入循环扩容
  * 如果sizeCtl大于0，表示第一个线程在进行扩容，如果CAS直接将sizeCtl的值设置为一个负数成功（这个负数的前16位表示resizeStamp，后16位表示正在扩容的线程数量），那么调用transfer方法进行扩容；失败进入循环扩容

```java
private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        boolean uncontended = true;
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended =
              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            // 创建累加单元数组和cell, 累加重试
            fullAddCount(x, uncontended);
            return;
        }
        if (check <= 1)
            return;
        s = sumCount();
    }
    // 从put函数调用的addCount，check一定大于等于0
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            if (sc < 0) {
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            // 此处第一次扩容为什么直接+2，因为-1表示容器正在初始化
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
// 通过这种方式扩容可以保证每次扩容得到的resizeStamp都不一样，因为Integer.numberOfLeadingZeros方法获取的是n表示的二进制数的第一个不为0的位数前面的0的个数，因为每次扩容的时候n不一样且为2的整数幂，所以每次得到的返回值都不一样，因此每次获取的resizeStamp都不一样。
// 同时这个方法的(1 << (RESIZE_STAMP_BITS - 1))这部分保证了从右到左的第16位一定是1.
static final int resizeStamp(int n) {
    return Integer.numberOfLeadingZeros(n) | (1 << (RESIZE_STAMP_BITS - 1));
}
```

首先使用线程的一个随机数计算要加入的数组的角标

### 累加重试—fullAddCount方法

```java
private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
    if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit();      // force initialization
        h = ThreadLocalRandom.getProbe();
        wasUncontended = true;
    }
    boolean collide = false;                // True if last slot nonempty
    for (;;) {
        CounterCell[] as; CounterCell a; int n; long v;
        if ((as = counterCells) != null && (n = as.length) > 0) {
            if ((a = as[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {            // Try to attach new Cell
                    CounterCell r = new CounterCell(x); // Optimistic create
                    if (cellsBusy == 0 &&
                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                        boolean created = false;
                        try {               // Recheck under lock
                            CounterCell[] rs; int m, j;
                            if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0;
                        }
                        if (created)
                            break;
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))
                break;
            else if (counterCells != as || n >= NCPU)
                collide = false;            // At max size or stale
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 &&
                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                try {
                    if (counterCells == as) {// Expand table unless stale
                        CounterCell[] rs = new CounterCell[n << 1];
                        for (int i = 0; i < n; ++i)
                            rs[i] = as[i];
                        counterCells = rs;
                    }
                } finally {
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            h = ThreadLocalRandom.advanceProbe(h);
        }
        else if (cellsBusy == 0 && counterCells == as &&
                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
            boolean init = false;
            try {                           // Initialize table
                if (counterCells == as) {
                    CounterCell[] rs = new CounterCell[2];
                    rs[h & 1] = new CounterCell(x);
                    counterCells = rs;
                    init = true;
                }
            } finally {
                cellsBusy = 0;
            }
            if (init)
                break;
        }
        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))
            break;                          // Fall back on using base
    }
}
```



### 扩容transfer方法

另种情况会调用transfer方法：

* 触发扩容的线程，传来的nextTab属性为null
* 协助扩容的线程，传来的nextTab属性不是null

首先会计算分配给线程的任务的步长stride，这个值一般是16

如果nextTable为null，表示当前线程是扩容的线程，需要创建nextTable

* 创建长度为原来2倍的Node数组
* 将创建出来的数组赋值给nextTable
* 将transferIndex属性赋值为n，原来table的长度

进入循环：

* 

```java
// tab是旧表，nextTab是一个两倍容量的空的新表
private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
        // stide是步长的意思，会将旧表按照这个步长进行分段，在并发扩容时，每个线程只负责自己段内数据的转移
        int n = tab.length, stride;
        // NCPU是当前系统的内核数，如果内核数只有一个，那么就不需要进行并发扩容，因为扩容是个纯计算密集型的逻辑，只有一个核心的时候反而得不偿失，因为无法真正的并发，反而会额外付出线程上下文切换的开销
        // 这里步长最小是16，也就是说每个线程最少要负责16个桶的数据迁移，这个值设置的太小会导致并发线程数增多，从而导致线程间的竞争变大，这个竞争是只下面的一些CAS逻辑，比如对transferIndex、sizeCtl变量的cas操作
        if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)
            stride = MIN_TRANSFER_STRIDE; // subdivide range
        if (nextTab == null) {            // initiating
            try {
                @SuppressWarnings("unchecked")
                // 如果新表没有初始化，则新建一个双倍容量的新表
                Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
                nextTab = nt;
            } catch (Throwable ex) {      // try to cope with OOME
                sizeCtl = Integer.MAX_VALUE;
                return;
            }
            nextTable = nextTab;
            // 设置【开始数据转移】的桶的下标，从尾部的桶开始往头部逐个处理，将transferIndex设置为老表的length（比最后一个桶的下标大1，所以后面的代码会-1）
            transferIndex = n;
        }
        int nextn = nextTab.length;
        // 生成用于表示【扩容中】状态的节点
        ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
        // 线程每次根据步长从数组上截取一段桶，如果线程处理完自己截取的一段内的桶后，还有未处理的数据，则需要重新从数组上截取一段来处理
        // true则标识当前线程需要继续在老表的数组上截取新的一段桶来处理数据（可能没有线程来帮忙，就只能自己一个人干完了）
        boolean advance = true;
        // 标记是否已结束扩容，做收尾工作
        boolean finishing = false; // to ensure sweep before committing nextTab
        // i是当前线程需要转移的桶的下标，bound是当前线程负责的桶的最小下标
        for (int i = 0, bound = 0;;) {
            Node<K,V> f; int fh;
            // 这个while的逻辑就是为了检查当前线程负责的段内的桶是否都处理完毕，如果处理完毕，则看下老表的数据里是否还有未处理的桶，如果有未处理的桶，则再次截取一段来处理
            while (advance) {
                int nextIndex, nextBound;
                // 如果下一个桶的下标（--i是下一个需要操作的桶的下标）还在自己负责的段内，就不需要截取新段了，就继续处理下一个桶的数据
                // 如果已经结束，则不需要继续截取新的段
                if (--i >= bound || finishing)
                    advance = false;
                // transferIndex用来表示这个下标及其后面的桶都已经被其他线程处理了，新的线程需要从transferIndex往前截取自己需要负责的桶，如果transferIndex小于等于0说明桶都已经转移完毕，不需要再处理了    
                else if ((nextIndex = transferIndex) <= 0) {
                    i = -1;
                    advance = false;
                }
                // 以nextIndex（在上面已经赋值为transferIndex）为起始位置，往数组头部方向截取相应步长的段来转移数据，通过cas将transferIndex设置到新的下标
                else if (U.compareAndSwapInt
                         (this, TRANSFERINDEX, nextIndex,
                          nextBound = (nextIndex > stride ?
                                       nextIndex - stride : 0))) {
                    // cas成功后，设置当前线程负责的下标边界（比如负责下标32到48的桶，那么这个bound就是32）
                    bound = nextBound;
                    // cas成功后，设置当前线程开始处理的桶的下标（比如负责下标32到48的桶，那么这个i就是48）
                    // transferIndex默认是从tab.length开始取值，所以要减1来表示正确的下标
                    i = nextIndex - 1;
                    // cas成功则表示当前线程已经成功截取了自己需要负责的一段数据了，不需要再往前截取了
                    advance = false;
                }
            }
            // i是需要转移的桶的下标，n是老表的容量
            // i<0说明旧表中的桶都已经转移完毕
            // i>=n|| i + n >= nextn 不是很明白这个判断条件，正常情况下，i作为开始转移的桶的下标肯定会小于老表的容量的，因为转移的是老表内的桶
            if (i < 0 || i >= n || i + n >= nextn) {
                int sc;
                // 判断是否已经完成扩容，已完成扩容则做收尾逻辑
                if (finishing) {
                    // 完成扩容后，将引用设置为null
                    nextTable = null;
                    // 将table引用指向新表，这里的table是个volatile变量，所以这个赋值操作对其他线程是可见的
                    table = nextTab;
                    // 设置新的扩容阈值，将阈值设置为新容量的3/4
                    // 这里的n是老表的容量，因为是双倍扩容，所以新表容量是2n，下面计算的结果是2n-0.5n = 1.5n，也就是新表容量的3/4
                    sizeCtl = (n << 1) - (n >>> 1);
                    // 返回结果，扩容结束
                    return;
                }
                // 在扩容开始时，会将sizeCtl设置成一个负数，每次有新的线程并发扩容时，会将sizeCtl+1，而当有线程处理完扩容逻辑后，再减1，以此来判断是否是最后一个线程
                if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                // cas成功，则判断当前线程是不是最后一个完成扩容的线程，由最后一个完成扩容逻辑的线程将finishing和advance设为true，重新循环到上面的if(finishing)里的收尾逻辑
                // 这里减2是因为在执行扩容的入口处，第一个触发扩容的线程会负责将sc加2，至于为什么第一个扩容的线程要加2，而不是加1，这个没理解
                    if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT)
                        return;
                    finishing = advance = true;
                    i = n; // recheck before commit
                }
            }
            // 如果是空桶，则在老表对应的下标出放一个ForwardingNode，在有别的线程往这个空桶写数据时会感知到扩容过程，一起来扩容
            else if ((f = tabAt(tab, i)) == null)
                advance = casTabAt(tab, i, null, fwd);
            // ForwardingNode节点的hash值就是MOVED（在ForwardingNode的构造方法里会设置hash值为MOVED），说明已经有线程处理了这个桶内的数据
            else if ((fh = f.hash) == MOVED)
                advance = true; // already processed
            else {
            // 在桶上加锁，防止对同一个桶数据并发操作
                synchronized (f) {
                // 有点双重校验锁的味道，防止获得锁后，该桶内数据被别的线程插入了新的数据，因为这个f是在未加锁之前获取的node对象，在这期间，可能这个下标处插入了新数据
                // 比如有别的线程调用了put方法往这个桶内链表插入新节点，这时候这个桶的node就变成了新插入的数据node（put操作会生成新的node，并将新node的next引用指向原node）
                // 如果不做这层校验，会导致新加入到桶内的数据没有被处理，导致数据丢失
                    if (tabAt(tab, i) == f) {
                        Node<K,V> ln, hn;
                        // fh>=0表示是正常的链表
                        if (fh >= 0) {
                        // 这里需要注意的是在put操作里是通过hash&(n-1)来选取下标位置，表容量n都是2的幂，所以这里hash&n的结果只有两个要么是n要么是0
                        // 值为0时的节点在新表的i下标出，而值为n的节点需要迁移到新表的i+n下标下，因为是双倍扩容
                        // 所以老表下标为i的桶内的数据在迁移rehash时，一半仍然在下标为i的桶内，另一半在i+n的桶内，不会出现第三种情况
                            int runBit = fh & n;
                            Node<K,V> lastRun = f;
                            // 这个循环的目的有两个
                            // 1、遍历出整个链表尾部不需要改变next指针的最长链，这样可以将这个链整个搬到新桶内，不用再逐个遍历了
                            // 2、由于是将老的完整节点链条搬到新桶内，所以也就不需要创建新的node节点，减少迁移过程中的gc压力
                            for (Node<K,V> p = f.next; p != null; p = p.next) {
                                int b = p.hash & n;
                                if (b != runBit) {
                                    runBit = b;
                                    lastRun = p;
                                }
                            }
                            if (runBit == 0) {
                                ln = lastRun;
                                hn = null;
                            }
                            else {
                                hn = lastRun;
                                ln = null;
                            }
                            for (Node<K,V> p = f; p != lastRun; p = p.next) {
                                int ph = p.hash; K pk = p.key; V pv = p.val;
                                // 逐个遍历节点，0表示仍然放到下标为i的桶内的链表
                                // 这里每次都是生成新的node对象而不修改原node对象的next指针，这也是get()方法不用加锁的关键所在
                                // 但是会带来gc压力，所以才有上面的那次遍历，希望减少对象的创建
                                if ((ph & n) == 0)
                                    ln = new Node<K,V>(ph, pk, pv, ln);
                                // 否则就是放到下标为i+n的桶内的链表
                                else
                                    hn = new Node<K,V>(ph, pk, pv, hn);
                            }
                            // 设置新表的下标为i的桶内数据
                            setTabAt(nextTab, i, ln);
                            // 设置新表的下标为i+n的桶内数据
                            setTabAt(nextTab, i + n, hn);
                            // 将老表下标为i的桶内放上ForwardingNode对象，用来标识当前处于扩容过程
                            setTabAt(tab, i, fwd);
                            // 处理完后，将这个字段设置为true，以便走到上面的while(advance)里检查当前线程负责的数据是否处理完成，并且查看是否需要截取新段
                            advance = true;
                        }
                        // 红黑树结构的迁移，逻辑与链表差不多，也是将整棵树拆成两颗，一棵树放到下标为i的桶内，一棵放到下标i+n的桶内
                        else if (f instanceof TreeBin) {
                            TreeBin<K,V> t = (TreeBin<K,V>)f;
                            TreeNode<K,V> lo = null, loTail = null;
                            TreeNode<K,V> hi = null, hiTail = null;
                            int lc = 0, hc = 0;
                            for (Node<K,V> e = t.first; e != null; e = e.next) {
                                int h = e.hash;
                                TreeNode<K,V> p = new TreeNode<K,V>
                                    (h, e.key, e.val, null, null);
                                if ((h & n) == 0) {
                                    if ((p.prev = loTail) == null)
                                        lo = p;
                                    else
                                        loTail.next = p;
                                    loTail = p;
                                    ++lc;
                                }
                                else {
                                    if ((p.prev = hiTail) == null)
                                        hi = p;
                                    else
                                        hiTail.next = p;
                                    hiTail = p;
                                    ++hc;
                                }
                            }
                            ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                                (hc != 0) ? new TreeBin<K,V>(lo) : t;
                            hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                                (lc != 0) ? new TreeBin<K,V>(hi) : t;
                            setTabAt(nextTab, i, ln);
                            setTabAt(nextTab, i + n, hn);
                            setTabAt(tab, i, fwd);
                            advance = true;
                        }
                    }
                }
            }
        }
    }
```

### remove方法

```java
// 将key以及对应的value从table中移除，如果key不存在，这个方法什么也不做。
public V remove(Object key) {
    return replaceNode(key, null, null);
}
// 当给定key的映射为value的时候，才将键值对进行删除
public boolean remove(Object key, Object value) {
    if (key == null)
        throw new NullPointerException();
    return value != null && replaceNode(key, null, value) != null;
}
// 当给定的key的映射为oldValue的时候，才将oldValue替换为newValue
public boolean replace(K key, V oldValue, V newValue) {
    if (key == null || oldValue == null || newValue == null)
        throw new NullPointerException();
    return replaceNode(key, newValue, oldValue) != null;
}
// 如果指定key有对应的value，那么将原来的value，替换为现在的value。
public V replace(K key, V value) {
    if (key == null || value == null)
        throw new NullPointerException();
    return replaceNode(key, value, null);
}
```

replaceNode方法和添加元素的putVal方法主要逻辑很相似。replaceNode方法删除数据，一共处理了三种情况：

1. table为空或者table对应索引位置table[index]为空

   说明没有匹配的键值对，也就不需要删除或者替换，直接返回null

2. table[index]的桶不为空，table[index]中的是ForwardingNode结点，此时table正在扩容。

   当前线程去协助进行数据迁移，table扩容完成之后，线程会进行自旋，重新执行相关操作

3. table[index]中的结点为其他三种情况，Node，TreeBin，ReservationNode，其中ReservationNode结点为临时结点，不会存储键值对，直接返回Null。

   为了防止冲突发生，需要先对桶位置上的table[index]进行加锁。

   如果table[index]桶类型为链表。遍历查找链表是否存在于key相等的结点，如果存在，保存旧值oldVal，并将结点从链表中删除，break掉循环；如果不存在与key相等的结点，直接返回null。

   如果table[index]桶类型为红黑树，从红黑树的根节点遍历查找与key相等的结点，如果存在，保存旧值，并将结点从红黑树中删除，break掉循环；如果不存在，返回null。

键值对删除完毕之后，调用addCount方法更新table中键值对的总数。

```java
final V replaceNode(Object key, V value, Object cv) {
    int hash = spread(key.hashCode());
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0 ||
            (f = tabAt(tab, i = (n - 1) & hash)) == null)
            break;
        else if ((fh = f.hash) == MOVED)
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            boolean validated = false;
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) {
                        validated = true;
                        for (Node<K,V> e = f, pred = null;;) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                V ev = e.val;
                                if (cv == null || cv == ev ||
                                    (ev != null && cv.equals(ev))) {
                                    oldVal = ev;
                                    if (value != null)
                                        e.val = value;
                                    else if (pred != null)
                                        pred.next = e.next;
                                    else
                                        setTabAt(tab, i, e.next);
                                }
                                break;
                            }
                            pred = e;
                            if ((e = e.next) == null)
                                break;
                        }
                    }
                    else if (f instanceof TreeBin) {
                        validated = true;
                        TreeBin<K,V> t = (TreeBin<K,V>)f;
                        TreeNode<K,V> r, p;
                        if ((r = t.root) != null &&
                            (p = r.findTreeNode(hash, key, null)) != null) {
                            V pv = p.val;
                            if (cv == null || cv == pv ||
                                (pv != null && cv.equals(pv))) {
                                oldVal = pv;
                                if (value != null)
                                    p.val = value;
                                else if (t.removeTreeNode(p))
                                    setTabAt(tab, i, untreeify(t.first));
                            }
                        }
                    }
                }
            }
            if (validated) {
                if (oldVal != null) {
                    if (value == null)
                        addCount(-1L, -1);
                    return oldVal;
                }
                break;
            }
        }
    }
    return null;
}
```

## ConcurrentLinkedQueue

在并发编程中，有时候需要使用线程安全的队列，如果要实现一个线程安全的队列有两种方式：

* 使用阻塞算法
* 使用非阻塞算法

使用阻塞算法的队列可以使用一个锁或者两把锁等方式来实现；非阻塞的实现方式则可以使用循环CAS的方式来实现。

ConcurrentLinkedQueue是一个基于链接结点的无界线程安全队列，它采用先进先出的规则对结点进行排序，当我们添加一个元素时，他会添加到队列尾部；当我们获取一个元素时，他会返回队列头部的元素。

### 核心属性

ConcurrentLinkedQueue是由head和tail节点组成的，每个结点（Node）由节点元素item和指向下一个结点next的引用组成，结点与结点之间就是通过这个next关联起来，从而组成一张链表结构的队列。默认情况下head结点存储的元素为空，tail结点等于head结点。

```java
private static class Node<E> {
    volatile E item;
    volatile Node<E> next;

    /**
     * Constructs a new node.  Uses relaxed write because item can
     * only be seen after publication via casNext.
     */
    Node(E item) {
        UNSAFE.putObject(this, itemOffset, item);
    }

    boolean casItem(E cmp, E val) {
        return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);
    }

    void lazySetNext(Node<E> val) {
        UNSAFE.putOrderedObject(this, nextOffset, val);
    }

    boolean casNext(Node<E> cmp, Node<E> val) {
        return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);
    }

    private static final sun.misc.Unsafe UNSAFE;
    private static final long itemOffset;
    private static final long nextOffset;

    static {
        try {
            UNSAFE = sun.misc.Unsafe.getUnsafe();
            Class<?> k = Node.class;
            itemOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField("item"));
            nextOffset = UNSAFE.objectFieldOffset
                (k.getDeclaredField("next"));
        } catch (Exception e) {
            throw new Error(e);
        }
    }
}

/**
 * A node from which the first live (non-deleted) node (if any)
 * can be reached in O(1) time.
 * Invariants:
 * - all live nodes are reachable from head via succ()
 * - head != null
 * - (tmp = head).next != tmp || tmp != head
 * Non-invariants:
 * - head.item may or may not be null.
 * - it is permitted for tail to lag behind head, that is, for tail
 *   to not be reachable from head!
 */
private transient volatile Node<E> head;

/**
 * A node from which the last node on list (that is, the unique
 * node with node.next == null) can be reached in O(1) time.
 * Invariants:
 * - the last node is always reachable from tail via succ()
 * - tail != null
 * Non-invariants:
 * - tail.item may or may not be null.
 * - it is permitted for tail to lag behind head, that is, for tail
 *   to not be reachable from head!
 * - tail.next may or may not be self-pointing to tail.
 */
private transient volatile Node<E> tail;
```

### 构造函数

```java
public ConcurrentLinkedQueue() {
    head = tail = new Node<E>(null);
}
```

### 入队列



## 阻塞队列

阻塞队列和普通队列的区别在于，阻塞队列提供两个附加操作的队列，提供了可阻塞的put和take方法。如果队列是空的，消费者使用take方法从队列中获取数据就会被阻塞，知道队列有数据可用；当队列是满的，生产者使用put方法向队列里添加数据就会被阻塞，直到队列中数据被消费有空闲位置可用。

JUC提供了7种适合与不同应用场景的阻塞队列：

* ArrayBlockingQueue：基于数组实现的有界阻塞队列
* LinkedBlockingQueue：基于链表实现的有界阻塞队列
* PriorityBlockingQueue：支持按优先级排序的无界阻塞队列
* DelayQueue：优先级队列实现的无界阻塞队列
* SynchronousQueue：不存储元素的阻塞队列
* LinkedTransferQueue：基于链表实现的无界阻塞队列
* LinkedBlockingDeque：基于链表实现的双向无界阻塞队列

7个阻塞队列全部实现了BlockingQueue接口，插入和移除元素分别各提供了4中处理函数：

|      | 抛出异常  | 返回特殊值 | 阻塞   | 超时               |
| ---- | --------- | ---------- | ------ | ------------------ |
| 插入 | add(e)    | offer(e)   | put(e) | offer(e,time,unit) |
| 删除 | remove()  | poll()     | take() | poll(time,unit)    |
| 检查 | element() | peek()     |        |                    |

插入操作：

* add(e)：当队列满时，继续插入元素会抛出IllegalStateException("Queue full")
* offer(e)：当队列满时，继续插入元素不会阻塞线程，直接返回false。如果插入成功，返回true
* put(e)：当队列满时，继续插入元素线程会被一直阻塞直到队列有空闲位置可用时为止
* offer(e,time,unit)：当队列满时，调用该方法的线程会被阻塞一段时间，乳沟超过指定时间还没有添加成功，线程直接退出。

移除操作：

* remove()：当队列为空时，调用该方法会抛出NoSuchElementException异常
* poll()：当队列为空时，调用该方法不会阻塞，直接返回null，当队列不为空时，则从队列中取出一个元素
* take()：当队列为空时，调用该方法会被一直阻塞直到队列有数据可用为止
* poll(time, unit)：当队列为空时，调用该方法的线程会被阻塞一段时间，如果超过指定时间

### ArrayBlockingQueue

ArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。

默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞的线程先访问队列。非公平性是对先等待的线程非公平的，当队列可用时，阻塞的线程可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。为了保证公平性，通常会降低吞吐量。

<img src="C:\Users\lfl\AppData\Roaming\Typora\typora-user-images\image-20220331103943005.png" alt="image-20220331103943005" style="zoom:50%;" />

ArrayBlockingQueue是一个有界阻塞队列，在初始化时需要指定容量大小，在生产者“生成”数据的速度和消费者消费数据的速度比较稳定且基本匹配的情况下，使用ArrayBlockingQueue是不错的选择。否则如果生产者产出数据素的大于消费者的消费速度，且当队列被填满的情况下，会有大量生产线程被阻塞。

ArrayBlockingQueue使用独占锁ReentrantLock来实现线程安全，出队和入队操作使用同一个锁对象，同时只能有一个线层进行入队和出队操作。这也就意味着生产者和消费者无法同时操作，在并发量一般的情况下基本够用，在高并发场景下，可能会成为性能瓶颈。

#### 构造函数

默认构造方法，指定队列初始容量，默认使用非公平锁策略

```java
public ArrayBlockingQueue(int capacity) {
    this(capacity, false);
}
```

指定队列初始容量以及使用公平锁还是非公平锁

```java
public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity <= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];// 初始化数组
    lock = new ReentrantLock(fair);// 初始化重入锁
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}
```

根据已有集合初始化阻塞队列。

构造函数中使用lock上锁，可以保证数据的可见性，保证在构造函数结束后，items，count，和putIndex

```java
public ArrayBlockingQueue(int capacity, boolean fair,
                          Collection<? extends E> c) {
    this(capacity, fair);

    final ReentrantLock lock = this.lock;
    lock.lock(); // Lock only for visibility, not mutual exclusion
    try {
        int i = 0;
        try {
            for (E e : c) {
                checkNotNull(e);
                items[i++] = e;
            }
        } catch (ArrayIndexOutOfBoundsException ex) {
            throw new IllegalArgumentException();
        }
        count = i;
        putIndex = (i == capacity) ? 0 : i;
    } finally {
        lock.unlock();
    }
}
```

#### 重要属性

```java
/** 保存队列元素的数组 */
final Object[] items;

/** 队尾元素index */
int takeIndex;

/** 下一个放置元素的位置index */
int putIndex;

/** 队列中元素个数 */
int count;

/** 全局锁，管理所有的访问 */
final ReentrantLock lock;

/** 非空条件变量 */
private final Condition notEmpty;

/** 非满条件变量 */
private final Condition notFull;

/**
 * Shared state for currently active iterators, or null if there
 * are known not to be any.  Allows queue operations to update
 * iterator state.
 */
transient Itrs itrs = null;
```

#### 插入元素

put(E e)方法：阻塞式插入元素

* 判断插入元素是否为null
* 使用lock上锁，保证只能是一个线程执行入队操作
* 如果队列是满的当前线程阻塞在notFull条件变量上，等待其他线程唤醒
* 如果队列有空闲位置可用，调用私有方法enqueue(E e)插入元素
* 最后释放锁

```java
public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}
private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    notEmpty.signal();
}
```

#### 移除元素

take()方法：阻塞式移除元素。

过程逻辑和put方法的一样。

```java
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}
```

#### 迭代器

### LinkedBlockingQueue

LinkedBlockingQueue是一个用链表实现的有界阻塞队列。此队列的默认长度和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。

LinkedBlockingQueue和ArrayBlockingQueue不同的是，它使用两把独立的锁takeLock和putLock来保证出队和入队操作线程安全，这样入队和出队之间可以真正的做到并发执行，同时可以有一个线程进行入队操作，另一个线程进行出队操作，这样比ArrayBlockingQueue提升了两倍的并发效率。

LinkedBlockingQueue默认使用非公平锁实现出入和入队内部的并发。

#### 重要属性

```java
/**
 * Linked list node class
 */
static class Node<E> {
    E item;

    /**
     * One of:
     * - the real successor Node
     * - this Node, meaning the successor is head.next
     * - null, meaning there is no successor (this is the last node)
     */
    Node<E> next;

    Node(E x) { item = x; }
}

/** 队列的最大容量，默认情况下为Integer.MAX_VALUE */
private final int capacity;

/** 阻塞队列现在的结点数量 */
private final AtomicInteger count = new AtomicInteger();

/**
 * 阻塞队列链表的头结点，头结点的item为null
 */
transient Node<E> head;

/**
 * 阻塞队列链表的尾结点，尾结点的next为null
 */
private transient Node<E> last;

/** take和poll操作所持有的锁，保证出队的安全 */
private final ReentrantLock takeLock = new ReentrantLock();

/** 当队列为空时线程的等待队列 */
private final Condition notEmpty = takeLock.newCondition();

/** put和offer操作所持有的锁，保证入队的安全 */
private final ReentrantLock putLock = new ReentrantLock();

/** 当队列满时线程的等待队列 */
private final Condition notFull = putLock.newCondition();
```

#### 构造函数

默认构造函数，LinkedBlockingQueue的capacity设置为Integer.MAX_VALUE

```java
public LinkedBlockingQueue() {
    this(Integer.MAX_VALUE);
}
```

指定初始容量的构造函数

```java
public LinkedBlockingQueue(int capacity) {
    if (capacity <= 0) throw new IllegalArgumentException();
    this.capacity = capacity;
    last = head = new Node<E>(null);
}
```

根据已有集合初始化队列的构造函数

```java
public LinkedBlockingQueue(Collection<? extends E> c) {
    this(Integer.MAX_VALUE);
    final ReentrantLock putLock = this.putLock;
    putLock.lock(); // Never contended, but necessary for visibility
    try {
        int n = 0;
        for (E e : c) {
            if (e == null)
                throw new NullPointerException();
            if (n == capacity)
                throw new IllegalStateException("Queue full");
            enqueue(new Node<E>(e));
            ++n;
        }
        count.set(n);
    } finally {
        putLock.unlock();
    }
}
```

#### 插入元素

* 判断插入元素是否为null，如果为null，抛出异常
* 执行putLock.lockInterruptibly()加锁，保证同时只能有一个线程执行入队操作。
* 如果队列是满的，当前线程会被阻塞，在notFull条件变量中等待被其他线程唤醒
* 如果队列没满，调用enqueue(e)在列表尾部插入元素
* 调用count.getAndIncrement递增元素个数，并计算递增之后队列中元素的个数，如果没有达到最大值，那么调用notFull.await方法唤醒其他插入元素的线程
* 入队结束后，解锁
* 如果入队前队列是空的，就可能有线程因为执行移除元素操作而被阻塞在notEmpty上，所以，当前线程入队完毕后，需要唤醒notEmpty中一个等待的线程，通知它队列上有元素可以获取。

```java
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    // Note: convention in all put/take/etc is to preset local var
    // holding count negative to indicate failure unless set.
    int c = -1;
    Node<E> node = new Node<E>(e);
    final ReentrantLock putLock = this.putLock;
    final AtomicInteger count = this.count;
    putLock.lockInterruptibly();
    try {
        /*
         * Note that count is used in wait guard even though it is
         * not protected by lock. This works because count can
         * only decrease at this point (all other puts are shut
         * out by lock), and we (or some other waiting put) are
         * signalled if it ever changes from capacity. Similarly
         * for all other uses of count in other wait guards.
         */
        while (count.get() == capacity) {
            notFull.await();
        }
        enqueue(node);
        c = count.getAndIncrement();
        if (c + 1 < capacity)
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    if (c == 0)
        signalNotEmpty();
}
private void enqueue(Node<E> node) {
    // assert putLock.isHeldByCurrentThread();
    // assert last.next == null;
    last = last.next = node;
}
```

#### 移除元素

```java
public E take() throws InterruptedException {
    E x;
    int c = -1;
    final AtomicInteger count = this.count;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();
    try {
        while (count.get() == 0) {
            notEmpty.await();
        }
        x = dequeue();
        c = count.getAndDecrement();
        if (c > 1)
            notEmpty.signal();
    } finally {
        takeLock.unlock();
    }
    if (c == capacity)
        signalNotFull();
    return x;
}
```







































































































































































































































